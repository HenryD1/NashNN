{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Networks for Game Theory",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HenryD1/NashNN/blob/master/Neural_Networks_for_Game_Theory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_-dLKkiQoo7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch as torch\n",
        "import inspect\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import types as types\n",
        "from tqdm import tqdm\n",
        "import collections\n",
        "import copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2H8Ar97fCno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Game Solvers { display-mode: \"code\" }\n",
        "## DESCRIPTION: THIS IS WHERE YOU PUT GAME SOLVER METHODS, INSIDE THIS CLASS\n",
        "\n",
        "class Game: \n",
        "\n",
        "  \n",
        "    ## DESCRIPTION OF gradDescent: VERY SHITTY METHOD, just SIMULTANOUS STEP OPTIMIZATIONS OF STRATEGIES FOR ALL PLAYERS\n",
        "\n",
        "    ## ASSUMES ALL PLAYERS HAVE TORCH TENSORS FOR STRATEGIES\n",
        "    def gradDescent(self, start_strategies, optimizers, max_epochs= 1000, noisy = False, epsilon = .1, epsilon_spread = 10):\n",
        "        strategy_parameters = []\n",
        "        for strategy in start_strategies:\n",
        "            if torch.is_tensor(strategy):\n",
        "                strategy_parameters.append([strategy])\n",
        "            elif isinstance(strategy, Player):\n",
        "                strategy_parameters.append(strategy.get_params())\n",
        "            elif isinstance(strategy, nn.Module):\n",
        "                strategy_parameters.append(strategy.parameters())\n",
        "            else:\n",
        "                raise Exception(\"One of these starting strategies was not an Class or a Tensor Yo\")\n",
        "        ##start_strategies must have grad enabled\n",
        "        ##This is to allow you to input just one optimizer\n",
        "        if not isinstance(optimizers, list):\n",
        "            optimizers = [optimizers for _ in range(len(self.players))]\n",
        "        ##Initialize some Optimizers\n",
        "        optim = [optimizers[i](strategy_parameters[i]) for i in range(len(self.players))]\n",
        "\n",
        "        def isolated_step(tuplet):\n",
        "            ###loss, optim, param = tuplet[0], tuplet[1], tuplet[2]\n",
        "            grad_ = torch.autograd.grad(tuplet[0], tuplet[2], retain_graph = True, allow_unused=True)\n",
        "            back = torch.autograd.backward(tuplet[2], grad_, retain_graph = True)\n",
        "            # tuplet[1].step()\n",
        "\n",
        "        #RUn THem\n",
        "\n",
        "\n",
        "        if noisy != False:\n",
        "            noisy_step = [noise/max_epochs for noise in noisy]\n",
        "        if epsilon != False:\n",
        "            epsilon_step = epsilon/max_epochs\n",
        "        for i in tqdm(range(max_epochs)):\n",
        "        # for i in range(max_epochs):\n",
        "            list(map(lambda x:x.zero_grad(),optim))\n",
        "            # if i % 100 == 0:\n",
        "            #     # print(rewards)\n",
        "            #     rewards = self.play(start_strategies)\n",
        "            #     (-rewards[0]).backward()\n",
        "            #     print(start_strategies[0].grad)\n",
        "            #     list(map(lambda x:x.zero_grad(),optim))\n",
        "\n",
        "            if noisy == False:\n",
        "                rewards = self.play(start_strategies)\n",
        "            else: \n",
        "                rewards = self.noisy_play(start_strategies, epsilon, noisy, [epsilon_spread for I in range(len(start_strategies))])\n",
        "            \n",
        "            niosy = [noise - noise_step for noise, noise_step in zip(noisy, noisy_step)]\n",
        "            epsilon = epsilon - epsilon_spread\n",
        "\n",
        "            # print(rewards)\n",
        "            loss = [-x for x in rewards]\n",
        "\n",
        "            list(map(isolated_step, zip(loss,optim,strategy_parameters)))\n",
        "            # if i % 100 == 0:\n",
        "            #     print(start_strategies[0].grad)\n",
        "            list(map(lambda x: x.step(), optim ))\n",
        "            \n",
        "            # for j in range(1):\n",
        "            #     print(j)\n",
        "            #     list(map(lambda x:x.zero_grad(),optim))\n",
        "            #     loss = [-x for x in self.play(start_strategies)]\n",
        "            #     loss[j].backward(retain_graph=True)\n",
        "            #     optim[j].step()\n",
        "\n",
        "            # for j in range(len(strategy_parameters)):\n",
        "            #     list(map(lambda x:x.zero_grad(),optim))\n",
        "            #     loss = [-x for x in self.play(start_strategies)]\n",
        "            #     isolated_step((loss[j],optim[j],strategy_parameters[j]))\n",
        "            \n",
        "        return start_strategies, [-x for x in loss]\n",
        "\n",
        "    def noisy_play(self, strats, epsilon, noise_array, epsilon_spread):\n",
        "        new_strat_array = []\n",
        "\n",
        "        class Noise_Strategy(Player):\n",
        "            def __init__(self, old_strategy, noise):\n",
        "                super(Noise_Strategy, self).__init__()\n",
        "                self.old_strategy = old_strategy\n",
        "                self.noise = noise\n",
        "            def forward(self, x):\n",
        "                no_noise_ans = self.old_strategy.forward(x) \n",
        "                return no_noise_ans + (torch.rand(no_noise_ans.shape) - .5) * self.noise\n",
        "            def get_params(self):\n",
        "                return self.old_strategy.get_params\n",
        "\n",
        "\n",
        "\n",
        "        class Random_Strategy(Player):\n",
        "            def __init__(self, old_strategy, spread):\n",
        "                super(Random_Strategy, self).__init__()\n",
        "                self.old_strategy = old_strategy\n",
        "                self.spread = spread\n",
        "            def forward(self, x):\n",
        "                no_noise_ans = self.old_strategy.forward(x) \n",
        "                return (torch.rand(no_noise_ans.shape) - .5) * self.spread + (no_noise_ans - no_noise_ans)\n",
        "\n",
        "            def get_params(self):\n",
        "                return []\n",
        "\n",
        "\n",
        "        for index, strategy in enumerate(strats):\n",
        "            if torch.is_tensor(strategy):\n",
        "                if np.random.rand() < epsilon:\n",
        "                    new_strat_array.append((strategy - strategy) + (torch.rand(strategy.shape)-.5)* epsilon_spread[index])\n",
        "                else:\n",
        "                    new_strat_array.append(strategy + (torch.rand(strategy.shape)-.5)* noise_array[index])\n",
        "            elif isinstance(strategy, Player):\n",
        "                if np.random.rand() < epsilon:\n",
        "                    new_strat_array.append(Random_Strategy(strategy, epsilon_spread[index]))\n",
        "                else:\n",
        "                    new_strat_array.append(Noise_Strategy(strategy, noise_array[index]))\n",
        "            else:\n",
        "                raise Exception(\"One of these starting strategies was not an Class or a Tensor Yo\")\n",
        "\n",
        "\n",
        "        \n",
        "        return self.play(new_strat_array)\n",
        "\n",
        "\n",
        "class Player:\n",
        "    pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HICDPRdnfER2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Games { display-mode: \"code\" }\n",
        "## MAKE NEW CLASSES HERE TO DESCRIBE NEW GAMES,, MAKE SURE EACH CLASS INHEREITS GAME\n",
        "\n",
        "## FOR EACH NEW GAME, MUST DEFINE: \n",
        "\n",
        "##self.players (A LIST OF PLAYER NAMES) (THIS HASNT COME IN HANDY YET BUT MAYBE IT WILL??? IDK, SEEMED LIKE A GOOD IDEA)\n",
        "\n",
        "##self.play (TAKE IN A LIST OF STRATEGIES, OUTPUT A LIST OF REWARDS), GOTTA KEEP EVERYTHING DIFFERENTIABLE\n",
        "\n",
        "##self.function_players A LIST OF PLAYERS WHO HAVE STRATEGIES THAT ARE FUNCTIONS\n",
        "\n",
        "## ADDITIONALLY IF YOU WOULD PLEASE PACK ALL INPUTS TO INIT BESIDES SELF INTO ONE LIST, THIS WOULD BE GREATLY APPRECIATED\n",
        "\n",
        "    \n",
        "class FourByFour(Game):\n",
        "    \n",
        "    ## DESCRIPTION: YO JUST INPUT A 3 DIMENSIONAL TENSOR INTO THIS BI*TCH, with the first axis indicating which player gets what reward, second two axes are normal ass payoff matrix, then BOOm\n",
        "    def __init__(self, payoff_mat):\n",
        "        self.players = [\"A\", \"B\"]\n",
        "        self.payoff_mat = payoff_mat\n",
        "        self.function_players = []\n",
        "    def play(self, strats):\n",
        "        # strats2 = [nn.functional.softmax(strat(torch.tensor([1.]))) for strat in strats]\n",
        "        strats2 = [nn.functional.softmax(strat) for strat in strats]\n",
        "\n",
        "        # strats1 = [torch.relu(strat) for strat in strats]\n",
        "        # strats2 = [strat/torch.sum(strat) for strat in strats1]\n",
        "        return [torch.einsum('a,ac,c->', strats2[0], self.payoff_mat[i,:,:], strats2[1]) for i in [0,1]]\n",
        "\n",
        "class FourByFourWNet(Game):\n",
        "    \n",
        "    ## DESCRIPTION: YO JUST INPUT A 3 DIMENSIONAL TENSOR INTO THIS BI*TCH, with the first axis indicating which player gets what reward, second two axes are normal ass payoff matrix, then BOOm\n",
        "    def __init__(self, payoff_mat):\n",
        "        self.players = [\"A\", \"B\"]\n",
        "        self.payoff_mat = payoff_mat\n",
        "        self.function_players = []\n",
        "    def play(self, strats):\n",
        "        strats2 = [nn.functional.softmax(strat.forward(torch.tensor([1.]))) for strat in strats]\n",
        "        # strats2 = [nn.functional.softmax(strat) for strat in strats]\n",
        "\n",
        "        # strats1 = [torch.relu(strat) for strat in strats]\n",
        "        # strats2 = [strat/torch.sum(strat) for strat in strats1]\n",
        "        return [torch.einsum('a,ac,c->', strats2[0], self.payoff_mat[i,:,:], strats2[1]) for i in [0,1]]\n",
        "\n",
        "\n",
        "# class PrisonersDilemma(Game):\n",
        "#     def __init__(self):\n",
        "#         self.players = [\"A\", \"B\"]\n",
        "#         self.payoff_mat = torch.tensor([[[-8,0], [-10,-1]], [-8,-10],[0,-1]], dtype = Float) \n",
        "#         self.function_players = []\n",
        "#     def play(self, strats):\n",
        "#         strats = [torch.relu(strat) for strat in strats]\n",
        "#         #take torch relu of what?\n",
        "#         strats = [strat/torch.sum(strat) for strat in strats]\n",
        "#         #this seems like some kind of renormalization given that you divide by the sum.\n",
        "#         return [torch.einsum('a,ac,c->', strats[0], self.payoff_mat[i,:,:], strats[1]) for i in [0,1]] #using einstein summation because I guess thats how we're doing this\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class NetworkPrincipalAgent(Game):\n",
        "    def __init__(self, adj_mat):\n",
        "        assert (adj_mat.shape[0] == adj_mat.shape[1] ) #this checks to see if the adjacency matrix is square.\n",
        "        self.num_nodes = adj_mat.shape[0]\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if i <= j:\n",
        "                    adj_mat[i,j] = 0\n",
        "                else: \n",
        "                    if adj_mat[i,j] != 0: #ok I see. We get a matrix with inputs already. And we set all nonzero inputs to 1 to clear for training.\n",
        "                        adj_mat[i,j] = 1\n",
        "        self.adj_mat = adj_mat\n",
        "        self.num_agents = torch.sum(self.adj_mat).type(torch.int32) #Ok got it, each one is the number of agents.\n",
        "        self.players = [\"principal\"] + [\"agent\" for _ in range(self.num_agents)]\n",
        "\n",
        "    # def transmission_prob(self, prob_nodes, prob_edges):\n",
        "    #     return (1 - torch.sum(1 - (prob_nodes * prob_edges)))\n",
        "\n",
        "    def play(self, strats):\n",
        "\n",
        "        distribution = (torch.abs(strats[0])/torch.sum(torch.abs(strats[0])))\n",
        "\n",
        "        # print(distribution)\n",
        "\n",
        "        effort = []\n",
        "\n",
        "        # for j in range(1,len(strats)):\n",
        "        #     effort.append(strats[j](distribution[j].reshape((1))))\n",
        "\n",
        "        for j in range(1,len(strats)):\n",
        "            effort.append(strats[j].forward(distribution))\n",
        "\n",
        "\n",
        "        strat_index = 0\n",
        "        realized_adj_matrix = self.adj_mat.detach().clone()\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if realized_adj_matrix[i,j] == 1:\n",
        "                    realized_adj_matrix[i,j] = torch.sigmoid(effort[strat_index])\n",
        "                    strat_index += 1\n",
        "        \n",
        "        # print(realized_adj_matrix)\n",
        "        \n",
        "        probability_vec = torch.zeros(1)\n",
        "        probability_vec[0] = 1\n",
        "\n",
        "        for node in range(1, num_nodes):\n",
        "            prob_nodes = probability_vec[:node]\n",
        "            prob_edges = realized_adj_matrix[node,:node]\n",
        "            # print(prob_edges)\n",
        "            # probability_vec[node] = (1 - torch.prod(1 - (prob_nodes * prob_edges)))\n",
        "            probability_vec = torch.cat((probability_vec, (1 - torch.prod(1 - (prob_nodes * prob_edges))).reshape((1))),0)\n",
        "      \n",
        "        # print(probability_vec)\n",
        "        \n",
        "        turnout = probability_vec[-1]\n",
        "\n",
        "        payoffs = []\n",
        "\n",
        "\n",
        "        for player in range(len(distribution)):\n",
        "            payoffs.append(distribution[player] * turnout)\n",
        "            if player > 0:\n",
        "                payoffs[-1] = ( 2 * self.num_agents * payoffs[-1]) - torch.sigmoid(effort[player-1])\n",
        "        payoffs[0] =  2 *self.num_agents * payoffs[0]\n",
        "        \n",
        "        return payoffs\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Producing_Game(Game):\n",
        "    def __init__(self, params):\n",
        "        self.num_workers, self.real_hour_cost, self.fake_hour_cost, self.max_hours, self.min_hours = params[0], params[1], params[2], params[3], params[4]\n",
        "\n",
        "\n",
        "    def play(self, strats):\n",
        "        for strat in strats[1:]:\n",
        "            for element in strat:\n",
        "                if element < self.min_hours:\n",
        "                    element = self.min_hours\n",
        "                if element > self.max_hours:\n",
        "                    element = self.max_hours\n",
        "        \n",
        "        prod_vec = torch.zeros(num_workers)\n",
        "        hour_vec = torch.zeros(num_workers)\n",
        "        for worker in range(1, self.num_workers+1):\n",
        "            hour_vec[worker] = torch.sum(strats[worker])\n",
        "            prod_vec[worker] = strats[worker][0] \n",
        "            unprod_vec [worker] = strats[worker][1]\n",
        "\n",
        "\n",
        "        distribution = params[0][1](hour_vec)\n",
        "        personal_payoff = params[0][0](torch.sum(prod_vec))\n",
        "        distribution = (distribution*(torch.sum(prod_vec) - personal_payoff)/(torch.sum(distribution))) - (self.real_hour_cost * prod_vec) - (self.fake_hour_cost * unprod_vec)\n",
        "\n",
        "        payoffs = [personal_payoff]\n",
        "\n",
        "        for i in range(distribution.shape[0]):\n",
        "            payoffs.append(distribution[i])\n",
        "\n",
        "        return payoffs\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfOn3r2Nh7jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "0c1844e3-6de2-4b4d-e8c6-931604b6afa7"
      },
      "source": [
        "#@title PD testing\n",
        "class PD_Worker(Player):\n",
        "    def __init__(self):\n",
        "        self.mat1 = (2*torch.rand([2,1]) - 1)\n",
        "        self.mat1.requires_grad = True\n",
        "        self.b = (2*torch.rand([2]) - 1)\n",
        "        self.b.requires_grad = True\n",
        "    def get_params(self):\n",
        "        return [self.mat1,self.b]\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      output = (self.mat1 @ x) + self.b\n",
        "\n",
        "      return output.reshape([-1])\n",
        "\n",
        "\n",
        "payoff_mat = torch.tensor([[[2.,-5.],[5.,-2.]],[[2.,5.],[-5.,-2.]]])\n",
        "\n",
        "PD = FourByFourWNet(payoff_mat)\n",
        "\n",
        "a = PD_Worker() \n",
        "print(a.forward(torch.tensor([1.])))\n",
        "\n",
        "\n",
        "\n",
        "# start_strats = [torch.tensor([1.,1.], requires_grad = True),torch.tensor([1.,1.], requires_grad = True)]\n",
        "\n",
        "start_strats = [PD_Worker() for _ in range(2)] \n",
        "# torch.autograd.set_detect_anomaly(True)\n",
        "Equilibrium = PD.gradDescent(start_strats, torch.optim.Adam)\n",
        "\n",
        "print([nn.functional.softmax(eq.forward(torch.tensor([1.]))) for eq in Equilibrium[0]])\n",
        "# # print([nn.functional.softmax(eq) for eq in Equilibrium[0]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-88c6121896c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mpayoff_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mPD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFourByFourWNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayoff_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsdQ_TK3HJhp",
        "colab_type": "text"
      },
      "source": [
        "List of Solver Methods Implemented:\n",
        "\n",
        "Chris: Shitty Naive Gradient Descent\n",
        "\n",
        "\n",
        "List of Games Implemented:\n",
        "\n",
        "Chris: Network Principal Agent Problem\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9XMznGAhTfJ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "bd5baf1f-5054-4919-c824-943ab0e05b09"
      },
      "source": [
        "#@title PD testing\n",
        "class PD_Worker(Player):\n",
        "    def __init__(self):\n",
        "      super(PD_Worker, self).__init__()\n",
        "      self.fc1 = nn.Linear(1, 2)\n",
        "      self.params = \n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      output = (self.fc1(x))\n",
        "\n",
        "      return output.reshape([-1])\n",
        "\n",
        "\n",
        "payoff_mat = torch.tensor([[[2.,-5.],[5.,-2.]],[[2.,5.],[-5.,-2.]]])\n",
        "\n",
        "PD = FourByFour(payoff_mat)\n",
        "\n",
        "# a = PD_Worker() \n",
        "# print(a(torch.tensor([1.,1.])))\n",
        "\n",
        "\n",
        "\n",
        "start_strats = [torch.tensor([1.,1.], requires_grad = True),torch.tensor([1.,1.], requires_grad = True)]\n",
        "\n",
        "# start_strats = [PD_Worker() for _ in range(2)] \n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "Equilibrium = PD.gradDescent(start_strats, torch.optim.Adam)\n",
        "\n",
        "# print([nn.functional.softmax(eq(torch.tensor([1.]))) for eq in Equilibrium[0]])\n",
        "print([nn.functional.softmax(eq) for eq in Equilibrium[0]])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-e80230e741e1>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    self.params =\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCxE_ZSmyFd-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5dd307f-be79-430b-901b-f86cf91652a9"
      },
      "source": [
        "#@title Network_Testing_1\n",
        "num_nodes = 5\n",
        "adj_mat = torch.zeros((num_nodes, num_nodes))\n",
        "for i in range(num_nodes):\n",
        "    for j in range(i):\n",
        "        adj_mat[i,j] = 1\n",
        "\n",
        "print(adj_mat)\n",
        "\n",
        "\n",
        "Network_game = NetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "num_workers = torch.sum(adj_mat).type(torch.int32)\n",
        "\n",
        "\n",
        "class Network_Worker(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Network_Worker, self).__init__()\n",
        "      self.fc1 = nn.Linear(1, 10)\n",
        "      self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      x1 = torch.relu(self.fc1(x))\n",
        "      output = torch.sigmoid(self.fc2(x1))\n",
        "\n",
        "      return output\n",
        "\n",
        "\n",
        "strats = [(torch.ones((num_workers + 1 )))] + [Network_Worker() for _ in range(num_workers)]\n",
        "strats[0].requires_grad = True\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "print(Network_game.play(strats))\n",
        "\n",
        "# Equilibrium = Network_game.gradDescent(strats, torch.optim.Adam)\n",
        "\n",
        "# print(Equilibrium[0])\n",
        "\n",
        "# print(Equilibrium[1])\n",
        "\n",
        "# print(Equilibrium[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0.]])\n",
            "[tensor(0.0857, grad_fn=<MulBackward0>), tensor([-0.5394], grad_fn=<SubBackward0>), tensor([-0.5090], grad_fn=<SubBackward0>), tensor([-0.5136], grad_fn=<SubBackward0>), tensor([-0.5536], grad_fn=<SubBackward0>), tensor([-0.5566], grad_fn=<SubBackward0>), tensor([-0.5323], grad_fn=<SubBackward0>), tensor([-0.5302], grad_fn=<SubBackward0>), tensor([-0.5537], grad_fn=<SubBackward0>), tensor([-0.5537], grad_fn=<SubBackward0>), tensor([-0.5103], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4kSnTSb2RSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fbc7f8a8-c757-439a-a156-8925997334be"
      },
      "source": [
        "num_nodes = 5\n",
        "adj_mat = torch.zeros((num_nodes, num_nodes))\n",
        "for i in range(num_nodes):\n",
        "    for j in range(i):\n",
        "        if not ((i == 4) & (j == 0)):\n",
        "            adj_mat[i,j] = 1\n",
        "\n",
        "print(adj_mat)\n",
        "\n",
        "\n",
        "num_workers = torch.sum(adj_mat).type(torch.int32)\n",
        "\n",
        "\n",
        "class Network_Worker(Player):\n",
        "    #manually implemented optimizer, need to include\n",
        "    def __init__(self):\n",
        "      super(Network_Worker, self).__init__()\n",
        "      self.m1 = (2*torch.rand([10,num_workers + 1]) - 1)\n",
        "      self.b1 = (2*torch.rand([10]) - 1)\n",
        "      self.m2 = (2*torch.rand([1,10]) - 1)\n",
        "      self.b2 = (2*torch.rand([1]) - 1)\n",
        "\n",
        "      self.m1.requires_grad = True\n",
        "      self.m2.requires_grad = True\n",
        "      self.b1.requires_grad = True\n",
        "      self.b2.requires_grad = True\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      x1 = torch.relu((self.m1 @ x) + self.b1)\n",
        "      output = (self.m2 @ x1 + self.b2)\n",
        "\n",
        "      return output\n",
        "    def get_params(self):\n",
        "        return [self.m1, self.m2, self.b1, self.b2]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Network_game = NetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "\n",
        "strats = [(torch.ones((num_workers + 1 )))] + [Network_Worker() for _ in range(num_workers)]\n",
        "strats[0].requires_grad = True\n",
        "\n",
        "# Network_game.play(strats)[0].backward()\n",
        "\n",
        "# print(strats[0].grad)\n",
        "\n",
        "\n",
        "# strats = [Principal()] + [Network_Worker() for _ in range(num_workers)]\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "# strats = [(torch.ones((num_workers + 1 )))] + [torch.tensor(0. ,requires_grad=True) for _ in range(num_workers)]\n",
        "# strats[0].requires_grad = True\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "\n",
        "Equilibrium = Network_game.gradDescent(strats, torch.optim.Adam, max_epochs=130000 , epsilon = 1, noisy = [.25 for _ in range(num_workers+ 1)] )\n",
        "\n",
        "\n",
        "\n",
        "# print(Equilibrium[1])\n",
        "\n",
        "# print(Equilibrium[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/160000 [00:00<3:22:54, 13.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [0., 1., 1., 1., 0.]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92%|█████████▏| 146404/160000 [3:06:36<19:01, 11.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30RVUYBI1UVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a9f5d70d-1867-4fbb-a744-ab10753e5082"
      },
      "source": [
        "copyeq = copy.deepcopy(Equilibrium[0])\n",
        "\n",
        "Equilibrium2 = Network_game.gradDescent(copyeq, torch.optim.Adam, max_epochs=100 , noisy = False )\n",
        "\n",
        "\n",
        "\n",
        "print(Equilibrium2)\n",
        "\n",
        "# print(Equilibrium2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([tensor([ 8.1934, -6.3482, -6.2592, -6.5436, -6.2945, -6.4667, -6.5307, -5.2570,\n",
            "        -5.9101, -6.6125, -6.2616], requires_grad=True), <__main__.Network_Worker object at 0x7fce1ec0c6a0>, <__main__.Network_Worker object at 0x7fce1ec0cda0>, <__main__.Network_Worker object at 0x7fce1ec0ccc0>, <__main__.Network_Worker object at 0x7fce1ec0cc50>, <__main__.Network_Worker object at 0x7fce1ec0cc88>, <__main__.Network_Worker object at 0x7fce1ec0cdd8>, <__main__.Network_Worker object at 0x7fce1ec0cb70>, <__main__.Network_Worker object at 0x7fce1ec0cd68>, <__main__.Network_Worker object at 0x7fce1ec0ceb8>, <__main__.Network_Worker object at 0x7fce1ec0ce48>], [tensor(0.0003, grad_fn=<NegBackward>), tensor([1.4052e-10], grad_fn=<NegBackward>), tensor([1.5342e-10], grad_fn=<NegBackward>), tensor([1.1549e-10], grad_fn=<NegBackward>), tensor([1.4757e-10], grad_fn=<NegBackward>), tensor([1.2468e-10], grad_fn=<NegBackward>), tensor([1.1645e-10], grad_fn=<NegBackward>), tensor([-1.4540e-05], grad_fn=<NegBackward>), tensor([2.1606e-10], grad_fn=<NegBackward>), tensor([1.0747e-10], grad_fn=<NegBackward>), tensor([1.5323e-10], grad_fn=<NegBackward>)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4PaMAGDHxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "outputId": "9bdc7b48-5aa6-4ca2-edb3-f54bb996e336"
      },
      "source": [
        "print(torch.abs(Equilibrium[0][0])/torch.sum(torch.abs(Equilibrium[0][0])))\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "print(Equilibrium[0][0].grad)\n",
        "\n",
        "indexs = [6,7]\n",
        "for index in indexs:\n",
        "    firstbot = Equilibrium[0][index]\n",
        "\n",
        "\n",
        "    dist = torch.abs(Equilibrium[0][0])/torch.sum(torch.abs(Equilibrium[0][0]))\n",
        "    x = torch.arange(100.)/100\n",
        "    y = []\n",
        "\n",
        "\n",
        "    for i in range(100):\n",
        "        dist2 = dist* (1 - (i / 100))/(torch.sum(dist) - dist[index])\n",
        "        dist2[index] = i/100\n",
        "        y.append(firstbot.forward(dist2))\n",
        "\n",
        "    y = torch.tensor(y)\n",
        "\n",
        "    plt.scatter(x,y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.9720, 0.0053, 0.0048, 0.0020, 0.0026, 0.0024, 0.0063, 0.0012, 0.0017,\n",
            "        0.0018], grad_fn=<DivBackward0>)\n",
            "tensor([ 2.6555e-12,  3.6715e-11, -6.8179e-12, -3.5190e-11, -2.9191e-11,\n",
            "        -1.0525e-11, -3.7650e-11,  2.9592e-11, -7.3813e-11, -4.6107e-11])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLvj1KoITBEW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "f2f2b55a-da17-4216-df66-3f1cd7b6fa45"
      },
      "source": [
        "\n",
        "# Network_game = NetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "# print(Network_game.play(Equilibrium[0]))\n",
        "\n",
        "# y = []\n",
        "# x = torch.arange(100.) - 50 \n",
        "# for i in range(len(x)):\n",
        "#     new_strats = Equilibrium[0].copy()\n",
        "#     class Fake_worker(nn.Module):\n",
        "#         def __init__(self):\n",
        "#             super(Fake_worker, self).__init__()\n",
        "#         def forward(self, x):\n",
        "#             return \n",
        "\n",
        "#     y.append(Network_game.play(new_strats))\n",
        "\n",
        "\n",
        "\n",
        "# # plt.scatter(x,y)\n",
        "\n",
        "yo = torch.abs(Equilibrium[0][0])/torch.sum(torch.abs(Equilibrium[0][0]))\n",
        "\n",
        "print(yo[0])\n",
        "realized_adj_matrix = Network_game.adj_mat.detach().clone()\n",
        "strat_index = 1\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        if not ((i == 4) & (j == 0)):\n",
        "            realized_adj_matrix[i,j] = yo[strat_index]\n",
        "            strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "\n",
        "print(Equilibrium[1])\n",
        "effort = []\n",
        "for strat in Equilibrium[0][1:]:\n",
        "    effort.append(torch.sigmoid(strat.forward(yo)))\n",
        "\n",
        "print(effort)\n",
        "strat_index = 0\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        if not ((i == 4) & (j == 0)):\n",
        "            realized_adj_matrix[i,j] = effort[strat_index]\n",
        "            strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "print(Network_game.play(Equilibrium[0]))\n",
        "print(Equilibrium[1])\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "print(Equilibrium[0][0].grad)\n",
        "\n",
        "print(Equilibrium[0][0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9720, grad_fn=<SelectBackward>)\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0053, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0048, 0.0020, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0026, 0.0024, 0.0063, 0.0000, 0.0000],\n",
            "        [0.0000, 0.0012, 0.0017, 0.0018, 0.0000]], grad_fn=<CopySlices>)\n",
            "[tensor(0., grad_fn=<NegBackward>), tensor([-2.0067e-12], grad_fn=<NegBackward>), tensor([-7.5301e-13], grad_fn=<NegBackward>), tensor([-2.2990e-13], grad_fn=<NegBackward>), tensor([-0.6289], grad_fn=<NegBackward>), tensor([-0.0727], grad_fn=<NegBackward>), tensor([-0.3568], grad_fn=<NegBackward>), tensor([-1.2314e-13], grad_fn=<NegBackward>), tensor([-2.4431e-13], grad_fn=<NegBackward>), tensor([-5.0333e-12], grad_fn=<NegBackward>)]\n",
            "[tensor([1.5581e-12], grad_fn=<SigmoidBackward>), tensor([5.7750e-13], grad_fn=<SigmoidBackward>), tensor([1.7026e-13], grad_fn=<SigmoidBackward>), tensor([2.5934e-12], grad_fn=<SigmoidBackward>), tensor([4.8253e-13], grad_fn=<SigmoidBackward>), tensor([6.9392e-13], grad_fn=<SigmoidBackward>), tensor([9.9119e-14], grad_fn=<SigmoidBackward>), tensor([1.7622e-13], grad_fn=<SigmoidBackward>), tensor([4.5856e-12], grad_fn=<SigmoidBackward>)]\n",
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.5581e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.7750e-13, 1.7026e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [2.5934e-12, 4.8253e-13, 6.9392e-13, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 9.9119e-14, 1.7622e-13, 4.5856e-12, 0.0000e+00]],\n",
            "       grad_fn=<CopySlices>)\n",
            "[tensor(0., grad_fn=<MulBackward0>), tensor([-1.5581e-12], grad_fn=<SubBackward0>), tensor([-5.7750e-13], grad_fn=<SubBackward0>), tensor([-1.7026e-13], grad_fn=<SubBackward0>), tensor([-2.5934e-12], grad_fn=<SubBackward0>), tensor([-4.8253e-13], grad_fn=<SubBackward0>), tensor([-6.9392e-13], grad_fn=<SubBackward0>), tensor([-9.9119e-14], grad_fn=<SubBackward0>), tensor([-1.7622e-13], grad_fn=<SubBackward0>), tensor([-4.5856e-12], grad_fn=<SubBackward0>)]\n",
            "[tensor(0., grad_fn=<NegBackward>), tensor([-2.0067e-12], grad_fn=<NegBackward>), tensor([-7.5301e-13], grad_fn=<NegBackward>), tensor([-2.2990e-13], grad_fn=<NegBackward>), tensor([-0.6289], grad_fn=<NegBackward>), tensor([-0.0727], grad_fn=<NegBackward>), tensor([-0.3568], grad_fn=<NegBackward>), tensor([-1.2314e-13], grad_fn=<NegBackward>), tensor([-2.4431e-13], grad_fn=<NegBackward>), tensor([-5.0333e-12], grad_fn=<NegBackward>)]\n",
            "tensor([ 2.6555e-12,  3.6715e-11, -6.8179e-12, -3.5190e-11, -2.9191e-11,\n",
            "        -1.0525e-11, -3.7650e-11,  2.9592e-11, -7.3813e-11, -4.6107e-11])\n",
            "tensor([ 5.1993, -0.0284,  0.0258,  0.0109, -0.0137,  0.0127,  0.0335, -0.0062,\n",
            "         0.0091, -0.0098], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwjwTSU81mpM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "810cbd4b-7641-4ebb-96ef-1da09545128e"
      },
      "source": [
        "strat_0 = Equilibrium[0][0]\n",
        "add_vec = torch.zeros([10])\n",
        "add_vec[7] = 1\n",
        "x = []\n",
        "y = []\n",
        "for i in range(200):\n",
        "    y.append(Network_game.play([strat_0 + (add_vec*(.1 * i))] + Equilibrium[0][1:])[0].item())\n",
        "    x.append(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.scatter(x,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f0265f664e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBhsU3C4c7po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "cd224260-6963-49d0-dd12-98568dfe683c"
      },
      "source": [
        "a = -torch.ones([11]) * 100\n",
        "a[7]  = 100\n",
        "a[0] = 100\n",
        "\n",
        "b = [a] + Equilibrium2[0][1:]\n",
        "\n",
        "print(Network_game.play(b))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(10.0000, grad_fn=<MulBackward0>), tensor([-8.3302e-12], grad_fn=<SubBackward0>), tensor([-3.4962e-12], grad_fn=<SubBackward0>), tensor([-6.7280e-12], grad_fn=<SubBackward0>), tensor([-3.9421e-12], grad_fn=<SubBackward0>), tensor([-7.0066e-12], grad_fn=<SubBackward0>), tensor([-2.0462e-11], grad_fn=<SubBackward0>), tensor([9.0000], grad_fn=<SubBackward0>), tensor([-2.1119e-11], grad_fn=<SubBackward0>), tensor([-2.8034e-11], grad_fn=<SubBackward0>), tensor([-6.6097e-12], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ktX04eNhtYq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "0e7274b9-bd8e-4d3b-9413-ebeab6288876"
      },
      "source": [
        "class DummyNetworkPrincipalAgent(Game):\n",
        "    def __init__(self, adj_mat):\n",
        "        assert (adj_mat.shape[0] == adj_mat.shape[1] ) #this checks to see if the adjacency matrix is square.\n",
        "        self.num_nodes = adj_mat.shape[0]\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if i <= j:\n",
        "                    adj_mat[i,j] = 0\n",
        "                else: \n",
        "                    if adj_mat[i,j] != 0: #ok I see. We get a matrix with inputs already. And we set all nonzero inputs to 1 to clear for training.\n",
        "                        adj_mat[i,j] = 1\n",
        "        self.adj_mat = adj_mat\n",
        "        self.num_agents = torch.sum(self.adj_mat).type(torch.int32) #Ok got it, each one is an agent.\n",
        "        self.players = [\"principal\"]\n",
        "\n",
        "    # def transmission_prob(self, prob_nodes, prob_edges):\n",
        "    #     return (1 - torch.sum(1 - (prob_nodes * prob_edges)))\n",
        "\n",
        "    def play(self, strats):\n",
        "\n",
        "        distribution = nn.functional.softmax(strats[0], dim = 0)\n",
        "\n",
        "        # print(distribution)\n",
        "\n",
        "        effort = []\n",
        "\n",
        "        # for j in range(1,len(strats)):\n",
        "        #     effort.append(strats[j](distribution[j].reshape((1))))\n",
        "\n",
        "        for j in range(1,len(strats)):\n",
        "            effort.append(strats[j](distribution))\n",
        "\n",
        "\n",
        "        strat_index = 0\n",
        "        realized_adj_matrix = self.adj_mat.detach().clone()\n",
        "        for i in range(self.num_nodes):\n",
        "            for j in range(self.num_nodes):\n",
        "                if realized_adj_matrix[i,j] == 1:\n",
        "                    realized_adj_matrix[i,j] = 1\n",
        "                    strat_index += 1\n",
        "        \n",
        "        # print(realized_adj_matrix)\n",
        "        \n",
        "        probability_vec = torch.zeros(1)\n",
        "        probability_vec[0] = 1\n",
        "\n",
        "        for node in range(1, num_nodes):\n",
        "            prob_nodes = probability_vec[:node]\n",
        "            prob_edges = realized_adj_matrix[node,:node]\n",
        "            # print(prob_edges)\n",
        "            # probability_vec[node] = (1 - torch.prod(1 - (prob_nodes * prob_edges)))\n",
        "            probability_vec = torch.cat((probability_vec, (1 - torch.prod(1 - (prob_nodes * prob_edges))).reshape((1))),0)\n",
        "      \n",
        "        # print(probability_vec)\n",
        "        \n",
        "        turnout = probability_vec[-1]\n",
        "\n",
        "        payoffs = []\n",
        "\n",
        "\n",
        "        for player in range(1):\n",
        "            payoffs.append(distribution[player] * turnout)\n",
        "            if player > 0:\n",
        "                payoffs[-1] = (2 * self.num_agents * payoffs[-1]) - torch.sigmoid(effort[player-1])\n",
        "        payoffs[0] = 2 * self.num_agents * payoffs[0]\n",
        "        \n",
        "        return payoffs\n",
        "\n",
        "num_nodes = 5\n",
        "adj_mat = torch.zeros((num_nodes, num_nodes))\n",
        "for i in range(num_nodes):\n",
        "    for j in range(i):\n",
        "        adj_mat[i,j] = 1\n",
        "\n",
        "print(adj_mat)\n",
        "\n",
        "\n",
        "num_workers = torch.sum(adj_mat).type(torch.int32)\n",
        "\n",
        "\n",
        "class Network_Worker(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Network_Worker, self).__init__()\n",
        "      self.fc1 = nn.Linear(num_workers + 1, 10)\n",
        "      self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      x1 = torch.relu(self.fc1(x))\n",
        "      output = (self.fc2(x1))\n",
        "\n",
        "      return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Network_game = DummyNetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "\n",
        "strats = [(torch.ones((num_workers + 1 )))] \n",
        "strats[0].requires_grad = True\n",
        "\n",
        "# strats = [Principal()] + [Network_Worker() for _ in range(num_workers)]\n",
        "\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "# strats = [(torch.ones((num_workers + 1 )))] + [torch.tensor(0. ,requires_grad=True) for _ in range(num_workers)]\n",
        "# strats[0].requires_grad = True\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(optimizer)\n",
        "Equilibrium = Network_game.gradDescent(strats, torch.optim.Adam, max_epochs=10000 , noisy = [.25])\n",
        "\n",
        "\n",
        "# print(Equilibrium[1])\n",
        "\n",
        "# print(Equilibrium[1])\n",
        "\n",
        "print(Equilibrium[0][0])\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "Equilibrium[0][0].grad\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 35/10000 [00:00<00:28, 345.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0.]])\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "[tensor(1.6746, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 1051/10000 [00:03<00:27, 329.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(10.6542, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 2045/10000 [00:06<00:23, 338.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(17.3384, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 3038/10000 [00:09<00:20, 334.30it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(18.9485, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 4034/10000 [00:12<00:17, 332.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(19.5109, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 51%|█████     | 5054/10000 [00:15<00:14, 337.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(19.7175, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 6047/10000 [00:18<00:11, 337.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(19.7892, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 7045/10000 [00:21<00:08, 336.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0050, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81%|████████  | 8068/10000 [00:24<00:05, 343.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(19.9338, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 91%|█████████ | 9058/10000 [00:27<00:02, 325.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(19.9613, grad_fn=<MulBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:30<00:00, 330.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([ 5.4948, -3.4834, -3.4836, -3.4845, -3.4848, -3.4829, -3.4830, -3.4853,\n",
            "        -3.4836, -3.4840, -3.4878], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 4.1096e-04,  1.1301e-05, -1.4041e-04,  2.9857e-04, -9.7140e-05,\n",
              "        -1.6387e-04,  1.0961e-04, -5.5141e-05, -1.9469e-04, -2.0230e-04,\n",
              "         2.0246e-05])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFFQIj73ipbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "33f16a6e-027e-4d66-d2dd-f5b1caee88e3"
      },
      "source": [
        "print(Equilibrium[0][0])\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "Equilibrium[0][0].grad\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 5.4948, -3.4834, -3.4836, -3.4845, -3.4848, -3.4829, -3.4830, -3.4853,\n",
            "        -3.4836, -3.4840, -3.4878], requires_grad=True)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0256, -0.0025, -0.0027, -0.0022, -0.0026, -0.0027, -0.0024, -0.0026,\n",
              "        -0.0027, -0.0027, -0.0025])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BF3LFHsiPdR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "d091bdc0-8835-4f76-e574-5713599a2562"
      },
      "source": [
        "\n",
        "# Network_game = NetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "# print(Network_game.play(Equilibrium[0]))\n",
        "\n",
        "# y = []\n",
        "# x = torch.arange(100.) - 50 \n",
        "# for i in range(len(x)):\n",
        "#     new_strats = Equilibrium[0].copy()\n",
        "#     class Fake_worker(nn.Module):\n",
        "#         def __init__(self):\n",
        "#             super(Fake_worker, self).__init__()\n",
        "#         def forward(self, x):\n",
        "#             return \n",
        "\n",
        "#     y.append(Network_game.play(new_strats))\n",
        "\n",
        "\n",
        "\n",
        "# # plt.scatter(x,y)\n",
        "\n",
        "yo = nn.functional.softmax(Equilibrium[0][0], dim = 0)\n",
        "\n",
        "print(yo[0])\n",
        "realized_adj_matrix = Network_game.adj_mat.detach().clone()\n",
        "strat_index = 1\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        realized_adj_matrix[i,j] = yo[strat_index]\n",
        "        strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "\n",
        "print(Equilibrium[1])\n",
        "effort = []\n",
        "for strat in Equilibrium[0][1:]:\n",
        "    effort.append(torch.sigmoid(strat(yo)))\n",
        "\n",
        "print(effort)\n",
        "strat_index = 0\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        realized_adj_matrix[i,j] = effort[strat_index]\n",
        "        strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "print(Network_game.play(Equilibrium[0]))\n",
        "print(Equilibrium[1])\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "Equilibrium[0][0].grad\n",
        "\n",
        "print(Equilibrium[0][0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1391, grad_fn=<SelectBackward>)\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0103, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.6842, 0.0149, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0166, 0.0165, 0.0122, 0.0000, 0.0000],\n",
            "        [0.0308, 0.0106, 0.0144, 0.0505, 0.0000]], grad_fn=<CopySlices>)\n",
            "[tensor(3.2457, grad_fn=<NegBackward>), tensor([0.2024], grad_fn=<NegBackward>), tensor([13.0443], grad_fn=<NegBackward>), tensor([0.3308], grad_fn=<NegBackward>), tensor([0.3174], grad_fn=<NegBackward>), tensor([0.3370], grad_fn=<NegBackward>), tensor([0.2467], grad_fn=<NegBackward>), tensor([-0.3505], grad_fn=<NegBackward>), tensor([0.2371], grad_fn=<NegBackward>), tensor([0.2847], grad_fn=<NegBackward>), tensor([0.8908], grad_fn=<NegBackward>)]\n",
            "[tensor([4.7767e-12], grad_fn=<SigmoidBackward>), tensor([2.6401e-12], grad_fn=<SigmoidBackward>), tensor([1.6351e-12], grad_fn=<SigmoidBackward>), tensor([6.7436e-13], grad_fn=<SigmoidBackward>), tensor([4.1638e-13], grad_fn=<SigmoidBackward>), tensor([9.1157e-13], grad_fn=<SigmoidBackward>), tensor([1.], grad_fn=<SigmoidBackward>), tensor([4.1836e-12], grad_fn=<SigmoidBackward>), tensor([1.1156e-12], grad_fn=<SigmoidBackward>), tensor([4.7812e-12], grad_fn=<SigmoidBackward>)]\n",
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [4.7767e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [2.6401e-12, 1.6351e-12, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [6.7436e-13, 4.1638e-13, 9.1157e-13, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 4.1836e-12, 1.1156e-12, 4.7812e-12, 0.0000e+00]],\n",
            "       grad_fn=<CopySlices>)\n",
            "[tensor(2.7810, grad_fn=<MulBackward0>), tensor([0.2053], grad_fn=<SubBackward0>), tensor([13.6844], grad_fn=<SubBackward0>), tensor([0.2989], grad_fn=<SubBackward0>), tensor([0.3312], grad_fn=<SubBackward0>), tensor([0.3303], grad_fn=<SubBackward0>), tensor([0.2435], grad_fn=<SubBackward0>), tensor([-0.3847], grad_fn=<SubBackward0>), tensor([0.2129], grad_fn=<SubBackward0>), tensor([0.2877], grad_fn=<SubBackward0>), tensor([1.0096], grad_fn=<SubBackward0>)]\n",
            "[tensor(3.2457, grad_fn=<NegBackward>), tensor([0.2024], grad_fn=<NegBackward>), tensor([13.0443], grad_fn=<NegBackward>), tensor([0.3308], grad_fn=<NegBackward>), tensor([0.3174], grad_fn=<NegBackward>), tensor([0.3370], grad_fn=<NegBackward>), tensor([0.2467], grad_fn=<NegBackward>), tensor([-0.3505], grad_fn=<NegBackward>), tensor([0.2371], grad_fn=<NegBackward>), tensor([0.2847], grad_fn=<NegBackward>), tensor([0.8908], grad_fn=<NegBackward>)]\n",
            "tensor([ 1.8317, -0.7745,  3.4251, -0.3988, -0.2963, -0.2988, -0.6039,  0.3232,\n",
            "        -0.7383, -0.4371,  0.8184], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fRvkEED58Cq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3872fc8-d36b-4ad0-dc7d-0f828ee14866"
      },
      "source": [
        "Equilibrium = Network_game.gradDescent(Equilibrium[0], torch.optim.Adam, max_epochs=40000 , noisy = [.25 for _ in range(num_workers+ 1)])\n",
        "yo = nn.functional.softmax(Equilibrium[0][0], dim = 0)\n",
        "\n",
        "print(yo[0])\n",
        "realized_adj_matrix = Network_game.adj_mat.detach().clone()\n",
        "strat_index = 1\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        realized_adj_matrix[i,j] = yo[strat_index]\n",
        "        strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "\n",
        "print(Equilibrium[1])\n",
        "effort = []\n",
        "for strat in Equilibrium[0][1:]:\n",
        "    effort.append(torch.sigmoid(strat(yo)))\n",
        "\n",
        "print(effort)\n",
        "strat_index = 0\n",
        "for i in range(5):\n",
        "    for j in range(i):\n",
        "        realized_adj_matrix[i,j] = effort[strat_index]\n",
        "        strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n",
        "\n",
        "print(Network_game.play(Equilibrium[0]))\n",
        "print(Equilibrium[1])\n",
        "Network_game.play(Equilibrium[0])[0].backward()\n",
        "\n",
        "Equilibrium[0][0].grad\n",
        "\n",
        "print(Equilibrium[0][0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 2/40000 [00:00<1:16:43,  8.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.5229, grad_fn=<MulBackward0>), tensor([0.0968], grad_fn=<SubBackward0>), tensor([6.5296], grad_fn=<SubBackward0>), tensor([-0.8208], grad_fn=<SubBackward0>), tensor([0.1796], grad_fn=<SubBackward0>), tensor([0.1684], grad_fn=<SubBackward0>), tensor([0.1115], grad_fn=<SubBackward0>), tensor([-0.2046], grad_fn=<SubBackward0>), tensor([0.0981], grad_fn=<SubBackward0>), tensor([-0.7383], grad_fn=<SubBackward0>), tensor([0.5321], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1002/40000 [02:04<1:22:28,  7.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0006, grad_fn=<MulBackward0>), tensor([0.0076], grad_fn=<SubBackward0>), tensor([0.0002], grad_fn=<SubBackward0>), tensor([0.0043], grad_fn=<SubBackward0>), tensor([1.2354], grad_fn=<SubBackward0>), tensor([0.0008], grad_fn=<SubBackward0>), tensor([0.1944], grad_fn=<SubBackward0>), tensor([0.1681], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.3130], grad_fn=<SubBackward0>), tensor([0.9690], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 2002/40000 [04:16<1:20:36,  7.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6305, grad_fn=<MulBackward0>), tensor([0.1931], grad_fn=<SubBackward0>), tensor([13.6439], grad_fn=<SubBackward0>), tensor([0.2885], grad_fn=<SubBackward0>), tensor([0.3214], grad_fn=<SubBackward0>), tensor([0.3661], grad_fn=<SubBackward0>), tensor([0.2387], grad_fn=<SubBackward0>), tensor([-0.4109], grad_fn=<SubBackward0>), tensor([0.2084], grad_fn=<SubBackward0>), tensor([0.2927], grad_fn=<SubBackward0>), tensor([1.1904], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 3002/40000 [06:23<1:18:27,  7.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8103, grad_fn=<MulBackward0>), tensor([0.2138], grad_fn=<SubBackward0>), tensor([13.3734], grad_fn=<SubBackward0>), tensor([0.3231], grad_fn=<SubBackward0>), tensor([0.3654], grad_fn=<SubBackward0>), tensor([0.3448], grad_fn=<SubBackward0>), tensor([0.2382], grad_fn=<SubBackward0>), tensor([-0.3800], grad_fn=<SubBackward0>), tensor([0.2004], grad_fn=<SubBackward0>), tensor([0.3260], grad_fn=<SubBackward0>), tensor([1.1659], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 4002/40000 [08:28<1:22:24,  7.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.7020, grad_fn=<MulBackward0>), tensor([0.1793], grad_fn=<SubBackward0>), tensor([13.8376], grad_fn=<SubBackward0>), tensor([0.3168], grad_fn=<SubBackward0>), tensor([0.2858], grad_fn=<SubBackward0>), tensor([0.3045], grad_fn=<SubBackward0>), tensor([0.2293], grad_fn=<SubBackward0>), tensor([-0.4019], grad_fn=<SubBackward0>), tensor([0.1720], grad_fn=<SubBackward0>), tensor([0.2808], grad_fn=<SubBackward0>), tensor([1.0792], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 5002/40000 [10:36<1:10:05,  8.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.9843, grad_fn=<MulBackward0>), tensor([0.2004], grad_fn=<SubBackward0>), tensor([13.2275], grad_fn=<SubBackward0>), tensor([0.2888], grad_fn=<SubBackward0>), tensor([0.3552], grad_fn=<SubBackward0>), tensor([0.4175], grad_fn=<SubBackward0>), tensor([0.2445], grad_fn=<SubBackward0>), tensor([-0.4202], grad_fn=<SubBackward0>), tensor([0.2491], grad_fn=<SubBackward0>), tensor([0.2399], grad_fn=<SubBackward0>), tensor([1.1234], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 6002/40000 [12:47<1:12:33,  7.81it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0368, grad_fn=<MulBackward0>), tensor([1.0350], grad_fn=<SubBackward0>), tensor([13.9173], grad_fn=<SubBackward0>), tensor([0.0934], grad_fn=<SubBackward0>), tensor([0.2198], grad_fn=<SubBackward0>), tensor([0.0781], grad_fn=<SubBackward0>), tensor([2.3569], grad_fn=<SubBackward0>), tensor([-0.6322], grad_fn=<SubBackward0>), tensor([0.0322], grad_fn=<SubBackward0>), tensor([0.4890], grad_fn=<SubBackward0>), tensor([1.3739], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 7002/40000 [14:56<1:09:45,  7.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.1121, grad_fn=<MulBackward0>), tensor([0.2024], grad_fn=<SubBackward0>), tensor([13.2866], grad_fn=<SubBackward0>), tensor([0.2975], grad_fn=<SubBackward0>), tensor([0.2998], grad_fn=<SubBackward0>), tensor([-0.6701], grad_fn=<SubBackward0>), tensor([0.2225], grad_fn=<SubBackward0>), tensor([-0.3979], grad_fn=<SubBackward0>), tensor([0.2211], grad_fn=<SubBackward0>), tensor([0.3266], grad_fn=<SubBackward0>), tensor([1.0893], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 8002/40000 [17:05<1:06:38,  8.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.4584, grad_fn=<MulBackward0>), tensor([0.1889], grad_fn=<SubBackward0>), tensor([14.1645], grad_fn=<SubBackward0>), tensor([0.2903], grad_fn=<SubBackward0>), tensor([0.2778], grad_fn=<SubBackward0>), tensor([0.3051], grad_fn=<SubBackward0>), tensor([0.2150], grad_fn=<SubBackward0>), tensor([-0.4679], grad_fn=<SubBackward0>), tensor([0.1842], grad_fn=<SubBackward0>), tensor([-0.4395], grad_fn=<SubBackward0>), tensor([1.0902], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 9002/40000 [19:11<1:05:21,  7.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6459, grad_fn=<MulBackward0>), tensor([0.2390], grad_fn=<SubBackward0>), tensor([13.6303], grad_fn=<SubBackward0>), tensor([0.3182], grad_fn=<SubBackward0>), tensor([0.3007], grad_fn=<SubBackward0>), tensor([0.3925], grad_fn=<SubBackward0>), tensor([0.2582], grad_fn=<SubBackward0>), tensor([-0.2938], grad_fn=<SubBackward0>), tensor([0.2196], grad_fn=<SubBackward0>), tensor([0.2927], grad_fn=<SubBackward0>), tensor([0.9967], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 10002/40000 [21:30<1:06:15,  7.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8322, grad_fn=<MulBackward0>), tensor([0.2328], grad_fn=<SubBackward0>), tensor([13.4922], grad_fn=<SubBackward0>), tensor([0.2971], grad_fn=<SubBackward0>), tensor([0.3428], grad_fn=<SubBackward0>), tensor([0.3797], grad_fn=<SubBackward0>), tensor([0.2687], grad_fn=<SubBackward0>), tensor([-0.3512], grad_fn=<SubBackward0>), tensor([0.2267], grad_fn=<SubBackward0>), tensor([0.3148], grad_fn=<SubBackward0>), tensor([0.9642], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 11001/40000 [23:41<1:02:14,  7.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6946, grad_fn=<MulBackward0>), tensor([0.2090], grad_fn=<SubBackward0>), tensor([13.4989], grad_fn=<SubBackward0>), tensor([0.3588], grad_fn=<SubBackward0>), tensor([0.3527], grad_fn=<SubBackward0>), tensor([0.3357], grad_fn=<SubBackward0>), tensor([0.2340], grad_fn=<SubBackward0>), tensor([-0.3669], grad_fn=<SubBackward0>), tensor([0.2514], grad_fn=<SubBackward0>), tensor([0.3483], grad_fn=<SubBackward0>), tensor([1.0738], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 12002/40000 [25:55<59:02,  7.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6622, grad_fn=<MulBackward0>), tensor([0.2233], grad_fn=<SubBackward0>), tensor([13.8475], grad_fn=<SubBackward0>), tensor([0.2858], grad_fn=<SubBackward0>), tensor([0.3371], grad_fn=<SubBackward0>), tensor([0.3493], grad_fn=<SubBackward0>), tensor([-0.7411], grad_fn=<SubBackward0>), tensor([-0.4194], grad_fn=<SubBackward0>), tensor([0.2024], grad_fn=<SubBackward0>), tensor([0.2596], grad_fn=<SubBackward0>), tensor([0.9308], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 13002/40000 [28:02<59:01,  7.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6234, grad_fn=<MulBackward0>), tensor([0.2362], grad_fn=<SubBackward0>), tensor([13.7023], grad_fn=<SubBackward0>), tensor([0.2646], grad_fn=<SubBackward0>), tensor([0.3164], grad_fn=<SubBackward0>), tensor([0.3807], grad_fn=<SubBackward0>), tensor([0.2353], grad_fn=<SubBackward0>), tensor([-0.2934], grad_fn=<SubBackward0>), tensor([0.2024], grad_fn=<SubBackward0>), tensor([0.2782], grad_fn=<SubBackward0>), tensor([1.0540], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 14002/40000 [30:11<1:00:05,  7.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.5973, grad_fn=<MulBackward0>), tensor([0.1946], grad_fn=<SubBackward0>), tensor([14.0978], grad_fn=<SubBackward0>), tensor([0.2911], grad_fn=<SubBackward0>), tensor([0.3287], grad_fn=<SubBackward0>), tensor([0.2794], grad_fn=<SubBackward0>), tensor([0.2218], grad_fn=<SubBackward0>), tensor([-0.4176], grad_fn=<SubBackward0>), tensor([0.1911], grad_fn=<SubBackward0>), tensor([0.2530], grad_fn=<SubBackward0>), tensor([0.0501], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 15002/40000 [32:18<56:07,  7.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.5331, grad_fn=<MulBackward0>), tensor([0.1776], grad_fn=<SubBackward0>), tensor([14.1723], grad_fn=<SubBackward0>), tensor([0.2273], grad_fn=<SubBackward0>), tensor([0.2859], grad_fn=<SubBackward0>), tensor([0.3204], grad_fn=<SubBackward0>), tensor([0.2447], grad_fn=<SubBackward0>), tensor([-0.4071], grad_fn=<SubBackward0>), tensor([0.1928], grad_fn=<SubBackward0>), tensor([0.2573], grad_fn=<SubBackward0>), tensor([0.9956], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40%|████      | 16002/40000 [34:28<55:07,  7.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8271, grad_fn=<MulBackward0>), tensor([0.1936], grad_fn=<SubBackward0>), tensor([13.4778], grad_fn=<SubBackward0>), tensor([0.2888], grad_fn=<SubBackward0>), tensor([0.3328], grad_fn=<SubBackward0>), tensor([0.3282], grad_fn=<SubBackward0>), tensor([0.2341], grad_fn=<SubBackward0>), tensor([-0.4811], grad_fn=<SubBackward0>), tensor([0.2087], grad_fn=<SubBackward0>), tensor([0.2790], grad_fn=<SubBackward0>), tensor([1.3107], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 43%|████▎     | 17002/40000 [36:38<47:25,  8.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.9253, grad_fn=<MulBackward0>), tensor([-0.3857], grad_fn=<SubBackward0>), tensor([13.1885], grad_fn=<SubBackward0>), tensor([0.2746], grad_fn=<SubBackward0>), tensor([0.3071], grad_fn=<SubBackward0>), tensor([0.3179], grad_fn=<SubBackward0>), tensor([0.2355], grad_fn=<SubBackward0>), tensor([-0.4859], grad_fn=<SubBackward0>), tensor([0.1906], grad_fn=<SubBackward0>), tensor([-0.7333], grad_fn=<SubBackward0>), tensor([1.1066], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45%|████▌     | 18002/40000 [38:46<47:01,  7.80it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6288, grad_fn=<MulBackward0>), tensor([-0.6945], grad_fn=<SubBackward0>), tensor([13.7820], grad_fn=<SubBackward0>), tensor([0.2677], grad_fn=<SubBackward0>), tensor([0.3418], grad_fn=<SubBackward0>), tensor([-0.6721], grad_fn=<SubBackward0>), tensor([0.2287], grad_fn=<SubBackward0>), tensor([-0.3844], grad_fn=<SubBackward0>), tensor([0.2053], grad_fn=<SubBackward0>), tensor([0.2984], grad_fn=<SubBackward0>), tensor([1.0809], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 19002/40000 [40:56<44:43,  7.82it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.3641, grad_fn=<MulBackward0>), tensor([0.2319], grad_fn=<SubBackward0>), tensor([14.1251], grad_fn=<SubBackward0>), tensor([0.2821], grad_fn=<SubBackward0>), tensor([0.3542], grad_fn=<SubBackward0>), tensor([0.2701], grad_fn=<SubBackward0>), tensor([0.2149], grad_fn=<SubBackward0>), tensor([-0.4986], grad_fn=<SubBackward0>), tensor([0.1766], grad_fn=<SubBackward0>), tensor([0.2677], grad_fn=<SubBackward0>), tensor([1.2120], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50%|█████     | 20002/40000 [43:02<41:00,  8.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.8876, grad_fn=<MulBackward0>), tensor([0.1035], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([1.5154], grad_fn=<SubBackward0>), tensor([0.0076], grad_fn=<SubBackward0>), tensor([12.5838], grad_fn=<SubBackward0>), tensor([0.0183], grad_fn=<SubBackward0>), tensor([1.8085], grad_fn=<SubBackward0>), tensor([0.1152], grad_fn=<SubBackward0>), tensor([0.6524], grad_fn=<SubBackward0>), tensor([1.2151], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 53%|█████▎    | 21002/40000 [45:12<44:38,  7.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.3854, grad_fn=<MulBackward0>), tensor([0.2280], grad_fn=<SubBackward0>), tensor([13.2929], grad_fn=<SubBackward0>), tensor([0.2853], grad_fn=<SubBackward0>), tensor([0.3078], grad_fn=<SubBackward0>), tensor([-0.6945], grad_fn=<SubBackward0>), tensor([0.2568], grad_fn=<SubBackward0>), tensor([-0.4022], grad_fn=<SubBackward0>), tensor([0.2165], grad_fn=<SubBackward0>), tensor([0.2665], grad_fn=<SubBackward0>), tensor([0.4126], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55%|█████▌    | 22002/40000 [47:20<39:05,  7.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.4952, grad_fn=<MulBackward0>), tensor([0.2178], grad_fn=<SubBackward0>), tensor([14.1704], grad_fn=<SubBackward0>), tensor([0.2403], grad_fn=<SubBackward0>), tensor([0.3442], grad_fn=<SubBackward0>), tensor([0.3303], grad_fn=<SubBackward0>), tensor([0.2587], grad_fn=<SubBackward0>), tensor([-0.5251], grad_fn=<SubBackward0>), tensor([0.1997], grad_fn=<SubBackward0>), tensor([0.2500], grad_fn=<SubBackward0>), tensor([0.8795], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 58%|█████▊    | 23002/40000 [49:27<38:22,  7.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.5476, grad_fn=<MulBackward0>), tensor([0.2154], grad_fn=<SubBackward0>), tensor([13.8558], grad_fn=<SubBackward0>), tensor([0.3382], grad_fn=<SubBackward0>), tensor([0.3051], grad_fn=<SubBackward0>), tensor([0.3582], grad_fn=<SubBackward0>), tensor([0.2403], grad_fn=<SubBackward0>), tensor([-0.3843], grad_fn=<SubBackward0>), tensor([0.1972], grad_fn=<SubBackward0>), tensor([0.2977], grad_fn=<SubBackward0>), tensor([1.0150], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 24002/40000 [51:34<33:12,  8.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.6763, grad_fn=<MulBackward0>), tensor([0.2314], grad_fn=<SubBackward0>), tensor([13.9201], grad_fn=<SubBackward0>), tensor([0.2727], grad_fn=<SubBackward0>), tensor([0.2924], grad_fn=<SubBackward0>), tensor([0.3399], grad_fn=<SubBackward0>), tensor([0.2526], grad_fn=<SubBackward0>), tensor([-0.4693], grad_fn=<SubBackward0>), tensor([0.2090], grad_fn=<SubBackward0>), tensor([0.1155], grad_fn=<SubBackward0>), tensor([1.0098], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 63%|██████▎   | 25002/40000 [53:40<30:56,  8.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.4173, grad_fn=<MulBackward0>), tensor([0.2150], grad_fn=<SubBackward0>), tensor([12.9233], grad_fn=<SubBackward0>), tensor([0.3101], grad_fn=<SubBackward0>), tensor([0.3283], grad_fn=<SubBackward0>), tensor([0.3001], grad_fn=<SubBackward0>), tensor([0.2435], grad_fn=<SubBackward0>), tensor([-0.3849], grad_fn=<SubBackward0>), tensor([0.2322], grad_fn=<SubBackward0>), tensor([0.2743], grad_fn=<SubBackward0>), tensor([1.1407], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▌   | 26002/40000 [55:48<28:59,  8.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.3745, grad_fn=<MulBackward0>), tensor([0.2037], grad_fn=<SubBackward0>), tensor([14.2770], grad_fn=<SubBackward0>), tensor([0.2572], grad_fn=<SubBackward0>), tensor([0.2849], grad_fn=<SubBackward0>), tensor([0.2809], grad_fn=<SubBackward0>), tensor([0.2364], grad_fn=<SubBackward0>), tensor([-0.4280], grad_fn=<SubBackward0>), tensor([0.2030], grad_fn=<SubBackward0>), tensor([0.2577], grad_fn=<SubBackward0>), tensor([1.0527], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 68%|██████▊   | 27001/40000 [58:03<28:36,  7.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.4976, grad_fn=<MulBackward0>), tensor([0.2532], grad_fn=<SubBackward0>), tensor([13.7836], grad_fn=<SubBackward0>), tensor([0.3076], grad_fn=<SubBackward0>), tensor([0.3163], grad_fn=<SubBackward0>), tensor([0.3512], grad_fn=<SubBackward0>), tensor([0.2711], grad_fn=<SubBackward0>), tensor([-0.3884], grad_fn=<SubBackward0>), tensor([0.2013], grad_fn=<SubBackward0>), tensor([0.2634], grad_fn=<SubBackward0>), tensor([1.1432], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70%|███████   | 28002/40000 [1:00:14<25:15,  7.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8589, grad_fn=<MulBackward0>), tensor([0.2470], grad_fn=<SubBackward0>), tensor([13.3471], grad_fn=<SubBackward0>), tensor([0.3017], grad_fn=<SubBackward0>), tensor([0.3137], grad_fn=<SubBackward0>), tensor([0.3638], grad_fn=<SubBackward0>), tensor([0.2993], grad_fn=<SubBackward0>), tensor([-0.4547], grad_fn=<SubBackward0>), tensor([0.2180], grad_fn=<SubBackward0>), tensor([0.2847], grad_fn=<SubBackward0>), tensor([1.2205], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|███████▎  | 29002/40000 [1:02:25<24:43,  7.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.0761, grad_fn=<MulBackward0>), tensor([0.2179], grad_fn=<SubBackward0>), tensor([13.3772], grad_fn=<SubBackward0>), tensor([0.3225], grad_fn=<SubBackward0>), tensor([0.3560], grad_fn=<SubBackward0>), tensor([0.3374], grad_fn=<SubBackward0>), tensor([0.0659], grad_fn=<SubBackward0>), tensor([-0.4508], grad_fn=<SubBackward0>), tensor([0.2070], grad_fn=<SubBackward0>), tensor([0.2634], grad_fn=<SubBackward0>), tensor([1.0325], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 75%|███████▌  | 30002/40000 [1:04:37<21:32,  7.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.9772, grad_fn=<MulBackward0>), tensor([0.2374], grad_fn=<SubBackward0>), tensor([13.6391], grad_fn=<SubBackward0>), tensor([0.2565], grad_fn=<SubBackward0>), tensor([0.2718], grad_fn=<SubBackward0>), tensor([0.3111], grad_fn=<SubBackward0>), tensor([0.2051], grad_fn=<SubBackward0>), tensor([-0.4233], grad_fn=<SubBackward0>), tensor([0.1871], grad_fn=<SubBackward0>), tensor([0.2616], grad_fn=<SubBackward0>), tensor([1.0493], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 31002/40000 [1:06:47<18:56,  7.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.2190, grad_fn=<MulBackward0>), tensor([0.2305], grad_fn=<SubBackward0>), tensor([12.9676], grad_fn=<SubBackward0>), tensor([0.3405], grad_fn=<SubBackward0>), tensor([0.3319], grad_fn=<SubBackward0>), tensor([0.3678], grad_fn=<SubBackward0>), tensor([-0.7449], grad_fn=<SubBackward0>), tensor([-0.3385], grad_fn=<SubBackward0>), tensor([0.2186], grad_fn=<SubBackward0>), tensor([0.3124], grad_fn=<SubBackward0>), tensor([1.0847], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80%|████████  | 32002/40000 [1:08:57<16:05,  8.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.1963, grad_fn=<MulBackward0>), tensor([-0.7797], grad_fn=<SubBackward0>), tensor([13.5610], grad_fn=<SubBackward0>), tensor([-0.7007], grad_fn=<SubBackward0>), tensor([0.3152], grad_fn=<SubBackward0>), tensor([0.3143], grad_fn=<SubBackward0>), tensor([0.2277], grad_fn=<SubBackward0>), tensor([-0.5115], grad_fn=<SubBackward0>), tensor([0.2239], grad_fn=<SubBackward0>), tensor([0.3246], grad_fn=<SubBackward0>), tensor([0.8516], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 83%|████████▎ | 33002/40000 [1:11:06<15:00,  7.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.4182, grad_fn=<MulBackward0>), tensor([0.2642], grad_fn=<SubBackward0>), tensor([12.8981], grad_fn=<SubBackward0>), tensor([0.2812], grad_fn=<SubBackward0>), tensor([0.3402], grad_fn=<SubBackward0>), tensor([0.3178], grad_fn=<SubBackward0>), tensor([0.2849], grad_fn=<SubBackward0>), tensor([-0.4576], grad_fn=<SubBackward0>), tensor([0.2133], grad_fn=<SubBackward0>), tensor([0.3328], grad_fn=<SubBackward0>), tensor([1.1069], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 85%|████████▌ | 34002/40000 [1:13:12<12:15,  8.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.7220, grad_fn=<MulBackward0>), tensor([0.2165], grad_fn=<SubBackward0>), tensor([13.7698], grad_fn=<SubBackward0>), tensor([0.3021], grad_fn=<SubBackward0>), tensor([-0.2235], grad_fn=<SubBackward0>), tensor([0.2909], grad_fn=<SubBackward0>), tensor([0.2748], grad_fn=<SubBackward0>), tensor([-0.4838], grad_fn=<SubBackward0>), tensor([0.1179], grad_fn=<SubBackward0>), tensor([0.3034], grad_fn=<SubBackward0>), tensor([0.8518], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 88%|████████▊ | 35002/40000 [1:15:19<10:47,  7.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.0486, grad_fn=<MulBackward0>), tensor([0.2865], grad_fn=<SubBackward0>), tensor([13.1332], grad_fn=<SubBackward0>), tensor([0.3099], grad_fn=<SubBackward0>), tensor([0.3790], grad_fn=<SubBackward0>), tensor([0.3225], grad_fn=<SubBackward0>), tensor([0.2967], grad_fn=<SubBackward0>), tensor([-0.4224], grad_fn=<SubBackward0>), tensor([0.2537], grad_fn=<SubBackward0>), tensor([0.3327], grad_fn=<SubBackward0>), tensor([1.0595], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 90%|█████████ | 36002/40000 [1:17:24<08:08,  8.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0825, grad_fn=<MulBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.3692], grad_fn=<SubBackward0>), tensor([0.0080], grad_fn=<SubBackward0>), tensor([0.0091], grad_fn=<SubBackward0>), tensor([0.0082], grad_fn=<SubBackward0>), tensor([0.0063], grad_fn=<SubBackward0>), tensor([-0.0113], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0091], grad_fn=<SubBackward0>), tensor([0.0271], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93%|█████████▎| 37002/40000 [1:19:34<06:19,  7.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.0677, grad_fn=<MulBackward0>), tensor([0.2449], grad_fn=<SubBackward0>), tensor([13.5808], grad_fn=<SubBackward0>), tensor([0.3076], grad_fn=<SubBackward0>), tensor([0.3414], grad_fn=<SubBackward0>), tensor([0.3031], grad_fn=<SubBackward0>), tensor([0.2506], grad_fn=<SubBackward0>), tensor([-0.4571], grad_fn=<SubBackward0>), tensor([0.1805], grad_fn=<SubBackward0>), tensor([0.2875], grad_fn=<SubBackward0>), tensor([0.8706], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 95%|█████████▌| 38002/40000 [1:21:41<04:22,  7.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.0763, grad_fn=<MulBackward0>), tensor([0.1422], grad_fn=<SubBackward0>), tensor([13.3249], grad_fn=<SubBackward0>), tensor([0.3072], grad_fn=<SubBackward0>), tensor([0.3459], grad_fn=<SubBackward0>), tensor([-0.5691], grad_fn=<SubBackward0>), tensor([0.2868], grad_fn=<SubBackward0>), tensor([-0.3970], grad_fn=<SubBackward0>), tensor([0.2027], grad_fn=<SubBackward0>), tensor([0.3102], grad_fn=<SubBackward0>), tensor([0.9682], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 98%|█████████▊| 39002/40000 [1:23:51<02:08,  7.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8685, grad_fn=<MulBackward0>), tensor([0.2204], grad_fn=<SubBackward0>), tensor([13.7337], grad_fn=<SubBackward0>), tensor([0.3076], grad_fn=<SubBackward0>), tensor([0.3463], grad_fn=<SubBackward0>), tensor([0.2916], grad_fn=<SubBackward0>), tensor([0.2265], grad_fn=<SubBackward0>), tensor([-0.3795], grad_fn=<SubBackward0>), tensor([0.2406], grad_fn=<SubBackward0>), tensor([0.3057], grad_fn=<SubBackward0>), tensor([0.8386], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40000/40000 [1:25:57<00:00,  7.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1530, grad_fn=<SelectBackward>)\n",
            "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0121, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [0.6667, 0.0166, 0.0000, 0.0000, 0.0000],\n",
            "        [0.0170, 0.0174, 0.0131, 0.0000, 0.0000],\n",
            "        [0.0300, 0.0112, 0.0155, 0.0475, 0.0000]], grad_fn=<CopySlices>)\n",
            "[tensor(0.0025, grad_fn=<NegBackward>), tensor([1.7799], grad_fn=<NegBackward>), tensor([4.9168], grad_fn=<NegBackward>), tensor([0.2758], grad_fn=<NegBackward>), tensor([0.5740], grad_fn=<NegBackward>), tensor([6.4046], grad_fn=<NegBackward>), tensor([0.0401], grad_fn=<NegBackward>), tensor([-0.9312], grad_fn=<NegBackward>), tensor([0.8099], grad_fn=<NegBackward>), tensor([5.1018], grad_fn=<NegBackward>), tensor([-0.9746], grad_fn=<NegBackward>)]\n",
            "[tensor([5.6496e-13], grad_fn=<SigmoidBackward>), tensor([5.1131e-13], grad_fn=<SigmoidBackward>), tensor([3.7894e-13], grad_fn=<SigmoidBackward>), tensor([1.2289e-13], grad_fn=<SigmoidBackward>), tensor([7.4124e-14], grad_fn=<SigmoidBackward>), tensor([1.4735e-13], grad_fn=<SigmoidBackward>), tensor([1.], grad_fn=<SigmoidBackward>), tensor([5.1762e-13], grad_fn=<SigmoidBackward>), tensor([2.4943e-13], grad_fn=<SigmoidBackward>), tensor([8.6912e-13], grad_fn=<SigmoidBackward>)]\n",
            "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.6496e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.1131e-13, 3.7894e-13, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.2289e-13, 7.4124e-14, 1.4735e-13, 0.0000e+00, 0.0000e+00],\n",
            "        [1.0000e+00, 5.1762e-13, 2.4943e-13, 8.6912e-13, 0.0000e+00]],\n",
            "       grad_fn=<CopySlices>)\n",
            "[tensor(3.0600, grad_fn=<MulBackward0>), tensor([0.2421], grad_fn=<SubBackward0>), tensor([13.3331], grad_fn=<SubBackward0>), tensor([0.3322], grad_fn=<SubBackward0>), tensor([0.3397], grad_fn=<SubBackward0>), tensor([0.3476], grad_fn=<SubBackward0>), tensor([0.2620], grad_fn=<SubBackward0>), tensor([-0.4001], grad_fn=<SubBackward0>), tensor([0.2242], grad_fn=<SubBackward0>), tensor([0.3093], grad_fn=<SubBackward0>), tensor([0.9499], grad_fn=<SubBackward0>)]\n",
            "[tensor(0.0025, grad_fn=<NegBackward>), tensor([1.7799], grad_fn=<NegBackward>), tensor([4.9168], grad_fn=<NegBackward>), tensor([0.2758], grad_fn=<NegBackward>), tensor([0.5740], grad_fn=<NegBackward>), tensor([6.4046], grad_fn=<NegBackward>), tensor([0.0401], grad_fn=<NegBackward>), tensor([-0.9312], grad_fn=<NegBackward>), tensor([0.8099], grad_fn=<NegBackward>), tensor([5.1018], grad_fn=<NegBackward>), tensor([-0.9746], grad_fn=<NegBackward>)]\n",
            "tensor([ 1.8361, -0.7009,  3.3080, -0.3842, -0.3619, -0.3389, -0.6218,  0.2067,\n",
            "        -0.7775, -0.4557,  0.6664], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahiku0D1MBb_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "786f7cef-0110-4a7e-ee29-1ce843460a35"
      },
      "source": [
        "num_nodes = 5\n",
        "adj_mat = torch.zeros((num_nodes, num_nodes))\n",
        "for i in range(num_nodes):\n",
        "    for j in range(i):\n",
        "        adj_mat[i,j] = 1\n",
        "\n",
        "print(adj_mat)\n",
        "\n",
        "\n",
        "class Network_Worker(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(Network_Worker, self).__init__()\n",
        "      self.fc1 = nn.Linear(num_workers + 1, 10)\n",
        "      self.fc2 = nn.Linear(10, 1)\n",
        "\n",
        "    # x represents our data\n",
        "    def forward(self, x):\n",
        "      x1 = torch.relu(self.fc1(x))\n",
        "      output = (self.fc2(x1))\n",
        "\n",
        "      return output\n",
        "\n",
        "\n",
        "Network_game = NetworkPrincipalAgent(adj_mat)\n",
        "\n",
        "num_workers = torch.sum(adj_mat).type(torch.int32)\n",
        "\n",
        "strats = [(torch.ones((num_workers + 1 )))] + [Network_Worker() for _ in range(num_workers)]\n",
        "strats[0].requires_grad = True\n",
        "torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "# strats = [(torch.ones((num_workers + 1 )))] + [torch.tensor(0. ,requires_grad=True) for _ in range(num_workers)]\n",
        "# strats[0].requires_grad = True\n",
        "\n",
        "# print(Network_game.play(strats))\n",
        "\n",
        "print(strats[2].parameters())\n",
        "optimizer = torch.optim.Adam(strats[2].parameters())\n",
        "\n",
        "print(optimizer)\n",
        "Equilibrium = Network_game.gradDescent(strats, torch.optim.Adam, max_epochs=30000 , noisy = [.25 for _ in range(num_workers+ 1)])\n",
        "\n",
        "yo = nn.functional.softmax(Equilibrium[0][0], dim = 0)\n",
        "realized_adj_matrix = Network_game.adj_mat.detach().clone()\n",
        "strat_index = 1\n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        if realized_adj_matrix[i,j] == 1:\n",
        "            realized_adj_matrix[i,j] = yo[strat_index]\n",
        "            strat_index += 1\n",
        "\n",
        "print(realized_adj_matrix)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 1/150000 [00:00<5:43:24,  7.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 0.]])\n",
            "<generator object Module.parameters at 0x7f3339e38830>\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "[tensor(0.0776, grad_fn=<MulBackward0>), tensor([1.0349], grad_fn=<SubBackward0>), tensor([1.0834], grad_fn=<SubBackward0>), tensor([1.1718], grad_fn=<SubBackward0>), tensor([0.9227], grad_fn=<SubBackward0>), tensor([1.2156], grad_fn=<SubBackward0>), tensor([1.0347], grad_fn=<SubBackward0>), tensor([1.0363], grad_fn=<SubBackward0>), tensor([1.0626], grad_fn=<SubBackward0>), tensor([1.0742], grad_fn=<SubBackward0>), tensor([0.9855], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 1002/150000 [02:07<5:27:46,  7.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0220, grad_fn=<MulBackward0>), tensor([2.0083], grad_fn=<SubBackward0>), tensor([1.9858], grad_fn=<SubBackward0>), tensor([1.9030], grad_fn=<SubBackward0>), tensor([0.9366], grad_fn=<SubBackward0>), tensor([1.9059], grad_fn=<SubBackward0>), tensor([1.8967], grad_fn=<SubBackward0>), tensor([1.0445], grad_fn=<SubBackward0>), tensor([1.9200], grad_fn=<SubBackward0>), tensor([2.0371], grad_fn=<SubBackward0>), tensor([0.9533], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  1%|▏         | 2002/150000 [04:16<5:17:19,  7.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0091, grad_fn=<MulBackward0>), tensor([2.0797], grad_fn=<SubBackward0>), tensor([2.0188], grad_fn=<SubBackward0>), tensor([1.8787], grad_fn=<SubBackward0>), tensor([0.9616], grad_fn=<SubBackward0>), tensor([1.8963], grad_fn=<SubBackward0>), tensor([1.9482], grad_fn=<SubBackward0>), tensor([1.8657], grad_fn=<SubBackward0>), tensor([1.9354], grad_fn=<SubBackward0>), tensor([2.0791], grad_fn=<SubBackward0>), tensor([1.0605], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 3002/150000 [06:24<5:15:53,  7.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0046, grad_fn=<MulBackward0>), tensor([2.0851], grad_fn=<SubBackward0>), tensor([1.9999], grad_fn=<SubBackward0>), tensor([1.8275], grad_fn=<SubBackward0>), tensor([0.9471], grad_fn=<SubBackward0>), tensor([1.8572], grad_fn=<SubBackward0>), tensor([1.9589], grad_fn=<SubBackward0>), tensor([2.1773], grad_fn=<SubBackward0>), tensor([1.9107], grad_fn=<SubBackward0>), tensor([2.0600], grad_fn=<SubBackward0>), tensor([1.0693], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 4002/150000 [08:32<5:20:15,  7.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0025, grad_fn=<MulBackward0>), tensor([2.0911], grad_fn=<SubBackward0>), tensor([1.9810], grad_fn=<SubBackward0>), tensor([1.7798], grad_fn=<SubBackward0>), tensor([0.9339], grad_fn=<SubBackward0>), tensor([1.8215], grad_fn=<SubBackward0>), tensor([1.9751], grad_fn=<SubBackward0>), tensor([2.3751], grad_fn=<SubBackward0>), tensor([1.8885], grad_fn=<SubBackward0>), tensor([2.0393], grad_fn=<SubBackward0>), tensor([1.0581], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  3%|▎         | 5002/150000 [10:40<5:08:23,  7.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0015, grad_fn=<MulBackward0>), tensor([2.0954], grad_fn=<SubBackward0>), tensor([1.9580], grad_fn=<SubBackward0>), tensor([1.7284], grad_fn=<SubBackward0>), tensor([0.9184], grad_fn=<SubBackward0>), tensor([1.7826], grad_fn=<SubBackward0>), tensor([1.9932], grad_fn=<SubBackward0>), tensor([2.5763], grad_fn=<SubBackward0>), tensor([1.8635], grad_fn=<SubBackward0>), tensor([2.0137], grad_fn=<SubBackward0>), tensor([1.0384], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  4%|▍         | 6002/150000 [12:47<5:05:44,  7.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0009, grad_fn=<MulBackward0>), tensor([2.0968], grad_fn=<SubBackward0>), tensor([1.9290], grad_fn=<SubBackward0>), tensor([1.6704], grad_fn=<SubBackward0>), tensor([0.8986], grad_fn=<SubBackward0>), tensor([1.7377], grad_fn=<SubBackward0>), tensor([2.0120], grad_fn=<SubBackward0>), tensor([2.8108], grad_fn=<SubBackward0>), tensor([1.8332], grad_fn=<SubBackward0>), tensor([1.9814], grad_fn=<SubBackward0>), tensor([1.0110], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▍         | 7002/150000 [14:53<5:04:00,  7.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0005, grad_fn=<MulBackward0>), tensor([2.0938], grad_fn=<SubBackward0>), tensor([1.8919], grad_fn=<SubBackward0>), tensor([1.6037], grad_fn=<SubBackward0>), tensor([0.8724], grad_fn=<SubBackward0>), tensor([1.6844], grad_fn=<SubBackward0>), tensor([2.0304], grad_fn=<SubBackward0>), tensor([3.1022], grad_fn=<SubBackward0>), tensor([1.7953], grad_fn=<SubBackward0>), tensor([1.9402], grad_fn=<SubBackward0>), tensor([0.9744], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 8002/150000 [17:00<4:56:57,  7.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0003, grad_fn=<MulBackward0>), tensor([2.0832], grad_fn=<SubBackward0>), tensor([1.8435], grad_fn=<SubBackward0>), tensor([1.5259], grad_fn=<SubBackward0>), tensor([0.8365], grad_fn=<SubBackward0>), tensor([1.6200], grad_fn=<SubBackward0>), tensor([2.0461], grad_fn=<SubBackward0>), tensor([3.4782], grad_fn=<SubBackward0>), tensor([1.7468], grad_fn=<SubBackward0>), tensor([1.8870], grad_fn=<SubBackward0>), tensor([0.9259], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  6%|▌         | 9002/150000 [19:07<5:11:08,  7.55it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0002, grad_fn=<MulBackward0>), tensor([2.0600], grad_fn=<SubBackward0>), tensor([1.7797], grad_fn=<SubBackward0>), tensor([1.4346], grad_fn=<SubBackward0>), tensor([0.7864], grad_fn=<SubBackward0>), tensor([1.5413], grad_fn=<SubBackward0>), tensor([2.0546], grad_fn=<SubBackward0>), tensor([3.9765], grad_fn=<SubBackward0>), tensor([1.6838], grad_fn=<SubBackward0>), tensor([1.8177], grad_fn=<SubBackward0>), tensor([0.8613], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 10002/150000 [21:14<4:57:32,  7.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.0001, grad_fn=<MulBackward0>), tensor([2.0166], grad_fn=<SubBackward0>), tensor([1.6949], grad_fn=<SubBackward0>), tensor([1.3270], grad_fn=<SubBackward0>), tensor([0.7160], grad_fn=<SubBackward0>), tensor([1.4444], grad_fn=<SubBackward0>), tensor([2.0478], grad_fn=<SubBackward0>), tensor([4.6486], grad_fn=<SubBackward0>), tensor([1.6008], grad_fn=<SubBackward0>), tensor([1.7267], grad_fn=<SubBackward0>), tensor([0.7747], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  7%|▋         | 11002/150000 [23:20<5:00:20,  7.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(7.6690e-05, grad_fn=<MulBackward0>), tensor([1.9412], grad_fn=<SubBackward0>), tensor([1.5820], grad_fn=<SubBackward0>), tensor([1.2004], grad_fn=<SubBackward0>), tensor([0.6177], grad_fn=<SubBackward0>), tensor([1.3248], grad_fn=<SubBackward0>), tensor([2.0129], grad_fn=<SubBackward0>), tensor([5.5617], grad_fn=<SubBackward0>), tensor([1.4915], grad_fn=<SubBackward0>), tensor([1.6073], grad_fn=<SubBackward0>), tensor([0.6589], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  8%|▊         | 12002/150000 [25:30<4:59:40,  7.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(4.6552e-05, grad_fn=<MulBackward0>), tensor([1.8196], grad_fn=<SubBackward0>), tensor([1.4340], grad_fn=<SubBackward0>), tensor([1.0533], grad_fn=<SubBackward0>), tensor([0.4804], grad_fn=<SubBackward0>), tensor([1.1790], grad_fn=<SubBackward0>), tensor([1.9317], grad_fn=<SubBackward0>), tensor([6.7932], grad_fn=<SubBackward0>), tensor([1.3493], grad_fn=<SubBackward0>), tensor([1.4525], grad_fn=<SubBackward0>), tensor([0.5059], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|▊         | 13002/150000 [27:40<5:02:43,  7.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.7876e-05, grad_fn=<MulBackward0>), tensor([1.6385], grad_fn=<SubBackward0>), tensor([1.2472], grad_fn=<SubBackward0>), tensor([0.8872], grad_fn=<SubBackward0>), tensor([0.2987], grad_fn=<SubBackward0>), tensor([1.0068], grad_fn=<SubBackward0>), tensor([1.7837], grad_fn=<SubBackward0>), tensor([8.3948], grad_fn=<SubBackward0>), tensor([1.1711], grad_fn=<SubBackward0>), tensor([1.2594], grad_fn=<SubBackward0>), tensor([0.3121], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  9%|▉         | 14002/150000 [29:48<4:46:15,  7.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.6423e-05, grad_fn=<MulBackward0>), tensor([1.4009], grad_fn=<SubBackward0>), tensor([1.0310], grad_fn=<SubBackward0>), tensor([0.7120], grad_fn=<SubBackward0>), tensor([0.0822], grad_fn=<SubBackward0>), tensor([0.8180], grad_fn=<SubBackward0>), tensor([1.5640], grad_fn=<SubBackward0>), tensor([10.3011], grad_fn=<SubBackward0>), tensor([0.9661], grad_fn=<SubBackward0>), tensor([1.0381], grad_fn=<SubBackward0>), tensor([0.0864], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10%|█         | 15002/150000 [31:56<4:41:23,  8.00it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(9.5102e-06, grad_fn=<MulBackward0>), tensor([1.1271], grad_fn=<SubBackward0>), tensor([0.8048], grad_fn=<SubBackward0>), tensor([0.5420], grad_fn=<SubBackward0>), tensor([-0.1495], grad_fn=<SubBackward0>), tensor([0.6292], grad_fn=<SubBackward0>), tensor([1.2877], grad_fn=<SubBackward0>), tensor([12.3470], grad_fn=<SubBackward0>), tensor([0.7527], grad_fn=<SubBackward0>), tensor([0.8083], grad_fn=<SubBackward0>), tensor([-0.1496], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|█         | 16002/150000 [34:04<4:45:15,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(5.4441e-06, grad_fn=<MulBackward0>), tensor([0.8553], grad_fn=<SubBackward0>), tensor([0.5962], grad_fn=<SubBackward0>), tensor([0.3938], grad_fn=<SubBackward0>), tensor([-0.3668], grad_fn=<SubBackward0>), tensor([0.4606], grad_fn=<SubBackward0>), tensor([0.9961], grad_fn=<SubBackward0>), tensor([14.2825], grad_fn=<SubBackward0>), tensor([0.5566], grad_fn=<SubBackward0>), tensor([0.5976], grad_fn=<SubBackward0>), tensor([-0.3718], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 11%|█▏        | 17002/150000 [36:12<4:43:13,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.1213e-06, grad_fn=<MulBackward0>), tensor([0.6235], grad_fn=<SubBackward0>), tensor([0.4268], grad_fn=<SubBackward0>), tensor([0.2779], grad_fn=<SubBackward0>), tensor([-0.5451], grad_fn=<SubBackward0>), tensor([0.3270], grad_fn=<SubBackward0>), tensor([0.7368], grad_fn=<SubBackward0>), tensor([15.8793], grad_fn=<SubBackward0>), tensor([0.3979], grad_fn=<SubBackward0>), tensor([0.4272], grad_fn=<SubBackward0>), tensor([-0.5513], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 12%|█▏        | 18002/150000 [38:20<4:37:02,  7.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.8109e-06, grad_fn=<MulBackward0>), tensor([0.4453], grad_fn=<SubBackward0>), tensor([0.3008], grad_fn=<SubBackward0>), tensor([0.1940], grad_fn=<SubBackward0>), tensor([-0.6785], grad_fn=<SubBackward0>), tensor([0.2291], grad_fn=<SubBackward0>), tensor([0.5322], grad_fn=<SubBackward0>), tensor([17.0799], grad_fn=<SubBackward0>), tensor([0.2804], grad_fn=<SubBackward0>), tensor([0.3008], grad_fn=<SubBackward0>), tensor([-0.6842], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 19002/150000 [40:27<4:46:06,  7.63it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.0658e-06, grad_fn=<MulBackward0>), tensor([0.3157], grad_fn=<SubBackward0>), tensor([0.2113], grad_fn=<SubBackward0>), tensor([0.1353], grad_fn=<SubBackward0>), tensor([-0.7739], grad_fn=<SubBackward0>), tensor([0.1602], grad_fn=<SubBackward0>), tensor([0.3800], grad_fn=<SubBackward0>), tensor([17.9421], grad_fn=<SubBackward0>), tensor([0.1967], grad_fn=<SubBackward0>), tensor([0.2112], grad_fn=<SubBackward0>), tensor([-0.7785], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 13%|█▎        | 20002/150000 [42:34<4:30:02,  8.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(6.3719e-07, grad_fn=<MulBackward0>), tensor([0.2238], grad_fn=<SubBackward0>), tensor([0.1488], grad_fn=<SubBackward0>), tensor([0.0948], grad_fn=<SubBackward0>), tensor([-0.8405], grad_fn=<SubBackward0>), tensor([0.1125], grad_fn=<SubBackward0>), tensor([0.2707], grad_fn=<SubBackward0>), tensor([18.5469], grad_fn=<SubBackward0>), tensor([0.1385], grad_fn=<SubBackward0>), tensor([0.1486], grad_fn=<SubBackward0>), tensor([-0.8441], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 14%|█▍        | 21002/150000 [44:40<4:42:13,  7.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.8553e-07, grad_fn=<MulBackward0>), tensor([0.1591], grad_fn=<SubBackward0>), tensor([0.1053], grad_fn=<SubBackward0>), tensor([0.0669], grad_fn=<SubBackward0>), tensor([-0.8870], grad_fn=<SubBackward0>), tensor([0.0795], grad_fn=<SubBackward0>), tensor([0.1931], grad_fn=<SubBackward0>), tensor([18.9698], grad_fn=<SubBackward0>), tensor([0.0979], grad_fn=<SubBackward0>), tensor([0.1051], grad_fn=<SubBackward0>), tensor([-0.8897], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▍        | 22002/150000 [46:45<4:25:30,  8.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.3621e-07, grad_fn=<MulBackward0>), tensor([0.1140], grad_fn=<SubBackward0>), tensor([0.0751], grad_fn=<SubBackward0>), tensor([0.0476], grad_fn=<SubBackward0>), tensor([-0.9193], grad_fn=<SubBackward0>), tensor([0.0566], grad_fn=<SubBackward0>), tensor([0.1386], grad_fn=<SubBackward0>), tensor([19.2638], grad_fn=<SubBackward0>), tensor([0.0699], grad_fn=<SubBackward0>), tensor([0.0750], grad_fn=<SubBackward0>), tensor([-0.9213], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15%|█▌        | 23002/150000 [48:53<4:29:48,  7.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.4644e-07, grad_fn=<MulBackward0>), tensor([0.0824], grad_fn=<SubBackward0>), tensor([0.0542], grad_fn=<SubBackward0>), tensor([0.0343], grad_fn=<SubBackward0>), tensor([-0.9418], grad_fn=<SubBackward0>), tensor([0.0408], grad_fn=<SubBackward0>), tensor([0.1004], grad_fn=<SubBackward0>), tensor([19.4686], grad_fn=<SubBackward0>), tensor([0.0504], grad_fn=<SubBackward0>), tensor([0.0540], grad_fn=<SubBackward0>), tensor([-0.9433], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 16%|█▌        | 24002/150000 [51:00<4:34:02,  7.66it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(9.1076e-08, grad_fn=<MulBackward0>), tensor([0.0597], grad_fn=<SubBackward0>), tensor([0.0392], grad_fn=<SubBackward0>), tensor([0.0248], grad_fn=<SubBackward0>), tensor([-0.9578], grad_fn=<SubBackward0>), tensor([0.0295], grad_fn=<SubBackward0>), tensor([0.0729], grad_fn=<SubBackward0>), tensor([19.6152], grad_fn=<SubBackward0>), tensor([0.0365], grad_fn=<SubBackward0>), tensor([0.0391], grad_fn=<SubBackward0>), tensor([-0.9590], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 25002/150000 [53:07<4:35:06,  7.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(5.6518e-08, grad_fn=<MulBackward0>), tensor([0.0433], grad_fn=<SubBackward0>), tensor([0.0283], grad_fn=<SubBackward0>), tensor([0.0179], grad_fn=<SubBackward0>), tensor([-0.9695], grad_fn=<SubBackward0>), tensor([0.0213], grad_fn=<SubBackward0>), tensor([0.0528], grad_fn=<SubBackward0>), tensor([19.7216], grad_fn=<SubBackward0>), tensor([0.0264], grad_fn=<SubBackward0>), tensor([0.0283], grad_fn=<SubBackward0>), tensor([-0.9703], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17%|█▋        | 26002/150000 [55:14<4:14:41,  8.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.6092e-08, grad_fn=<MulBackward0>), tensor([0.0323], grad_fn=<SubBackward0>), tensor([0.0211], grad_fn=<SubBackward0>), tensor([0.0133], grad_fn=<SubBackward0>), tensor([-0.9772], grad_fn=<SubBackward0>), tensor([0.0159], grad_fn=<SubBackward0>), tensor([0.0395], grad_fn=<SubBackward0>), tensor([19.7922], grad_fn=<SubBackward0>), tensor([0.0197], grad_fn=<SubBackward0>), tensor([0.0211], grad_fn=<SubBackward0>), tensor([-0.9779], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 27002/150000 [57:23<4:21:03,  7.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.3442e-08, grad_fn=<MulBackward0>), tensor([0.0247], grad_fn=<SubBackward0>), tensor([0.0162], grad_fn=<SubBackward0>), tensor([0.0102], grad_fn=<SubBackward0>), tensor([-0.9826], grad_fn=<SubBackward0>), tensor([0.0121], grad_fn=<SubBackward0>), tensor([0.0302], grad_fn=<SubBackward0>), tensor([19.8411], grad_fn=<SubBackward0>), tensor([0.0150], grad_fn=<SubBackward0>), tensor([0.0161], grad_fn=<SubBackward0>), tensor([-0.9831], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▊        | 28001/150000 [59:42<5:22:18,  6.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.5231e-08, grad_fn=<MulBackward0>), tensor([0.0191], grad_fn=<SubBackward0>), tensor([0.0125], grad_fn=<SubBackward0>), tensor([0.0079], grad_fn=<SubBackward0>), tensor([-0.9866], grad_fn=<SubBackward0>), tensor([0.0094], grad_fn=<SubBackward0>), tensor([0.0233], grad_fn=<SubBackward0>), tensor([19.8775], grad_fn=<SubBackward0>), tensor([0.0116], grad_fn=<SubBackward0>), tensor([0.0124], grad_fn=<SubBackward0>), tensor([-0.9870], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 29001/150000 [1:01:59<4:57:12,  6.79it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.0453e-08, grad_fn=<MulBackward0>), tensor([0.0158], grad_fn=<SubBackward0>), tensor([0.0103], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([-0.9889], grad_fn=<SubBackward0>), tensor([0.0077], grad_fn=<SubBackward0>), tensor([0.0193], grad_fn=<SubBackward0>), tensor([19.8987], grad_fn=<SubBackward0>), tensor([0.0096], grad_fn=<SubBackward0>), tensor([0.0103], grad_fn=<SubBackward0>), tensor([-0.9892], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20%|██        | 30002/150000 [1:04:23<4:15:20,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(7.5217e-09, grad_fn=<MulBackward0>), tensor([0.0139], grad_fn=<SubBackward0>), tensor([0.0091], grad_fn=<SubBackward0>), tensor([0.0057], grad_fn=<SubBackward0>), tensor([-0.9902], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([0.0171], grad_fn=<SubBackward0>), tensor([19.9104], grad_fn=<SubBackward0>), tensor([0.0085], grad_fn=<SubBackward0>), tensor([0.0091], grad_fn=<SubBackward0>), tensor([-0.9905], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██        | 31002/150000 [1:06:41<4:34:35,  7.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(5.4155e-09, grad_fn=<MulBackward0>), tensor([0.0127], grad_fn=<SubBackward0>), tensor([0.0083], grad_fn=<SubBackward0>), tensor([0.0052], grad_fn=<SubBackward0>), tensor([-0.9910], grad_fn=<SubBackward0>), tensor([0.0062], grad_fn=<SubBackward0>), tensor([0.0156], grad_fn=<SubBackward0>), tensor([19.9181], grad_fn=<SubBackward0>), tensor([0.0077], grad_fn=<SubBackward0>), tensor([0.0083], grad_fn=<SubBackward0>), tensor([-0.9913], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 21%|██▏       | 32002/150000 [1:09:09<4:24:33,  7.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.9609e-09, grad_fn=<MulBackward0>), tensor([0.0122], grad_fn=<SubBackward0>), tensor([0.0080], grad_fn=<SubBackward0>), tensor([0.0050], grad_fn=<SubBackward0>), tensor([-0.9914], grad_fn=<SubBackward0>), tensor([0.0060], grad_fn=<SubBackward0>), tensor([0.0150], grad_fn=<SubBackward0>), tensor([19.9215], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([0.0080], grad_fn=<SubBackward0>), tensor([-0.9917], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 33002/150000 [1:11:31<4:33:53,  7.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.8204e-09, grad_fn=<MulBackward0>), tensor([0.0118], grad_fn=<SubBackward0>), tensor([0.0077], grad_fn=<SubBackward0>), tensor([0.0049], grad_fn=<SubBackward0>), tensor([-0.9917], grad_fn=<SubBackward0>), tensor([0.0058], grad_fn=<SubBackward0>), tensor([0.0145], grad_fn=<SubBackward0>), tensor([19.9241], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.0077], grad_fn=<SubBackward0>), tensor([-0.9919], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 34002/150000 [1:13:49<4:02:40,  7.97it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.9730e-09, grad_fn=<MulBackward0>), tensor([0.0114], grad_fn=<SubBackward0>), tensor([0.0075], grad_fn=<SubBackward0>), tensor([0.0047], grad_fn=<SubBackward0>), tensor([-0.9920], grad_fn=<SubBackward0>), tensor([0.0056], grad_fn=<SubBackward0>), tensor([0.0140], grad_fn=<SubBackward0>), tensor([19.9266], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0075], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 23%|██▎       | 35002/150000 [1:15:59<4:08:39,  7.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.3948e-09, grad_fn=<MulBackward0>), tensor([0.0113], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([0.0047], grad_fn=<SubBackward0>), tensor([-0.9920], grad_fn=<SubBackward0>), tensor([0.0056], grad_fn=<SubBackward0>), tensor([0.0139], grad_fn=<SubBackward0>), tensor([19.9270], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 24%|██▍       | 36002/150000 [1:18:11<4:01:26,  7.87it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(9.6010e-10, grad_fn=<MulBackward0>), tensor([0.0110], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.0045], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>), tensor([0.0054], grad_fn=<SubBackward0>), tensor([0.0135], grad_fn=<SubBackward0>), tensor([19.9292], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▍       | 37002/150000 [1:20:22<3:59:49,  7.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(6.7222e-10, grad_fn=<MulBackward0>), tensor([0.0108], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0132], grad_fn=<SubBackward0>), tensor([19.9307], grad_fn=<SubBackward0>), tensor([0.0066], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9926], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|██▌       | 38002/150000 [1:22:28<3:57:21,  7.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(4.8023e-10, grad_fn=<MulBackward0>), tensor([0.0106], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0043], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>), tensor([0.0052], grad_fn=<SubBackward0>), tensor([0.0130], grad_fn=<SubBackward0>), tensor([19.9320], grad_fn=<SubBackward0>), tensor([0.0064], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([-0.9928], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 26%|██▌       | 39002/150000 [1:24:35<3:52:58,  7.94it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.6124e-10, grad_fn=<MulBackward0>), tensor([0.0107], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0132], grad_fn=<SubBackward0>), tensor([19.9310], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 40002/150000 [1:26:41<3:52:36,  7.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.7263e-10, grad_fn=<MulBackward0>), tensor([0.0107], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0132], grad_fn=<SubBackward0>), tensor([19.9311], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|██▋       | 41002/150000 [1:28:47<3:57:29,  7.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.0644e-10, grad_fn=<MulBackward0>), tensor([0.0104], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([0.0043], grad_fn=<SubBackward0>), tensor([-0.9926], grad_fn=<SubBackward0>), tensor([0.0052], grad_fn=<SubBackward0>), tensor([0.0129], grad_fn=<SubBackward0>), tensor([19.9327], grad_fn=<SubBackward0>), tensor([0.0064], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([-0.9928], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 28%|██▊       | 42002/150000 [1:30:54<3:49:54,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.6410e-10, grad_fn=<MulBackward0>), tensor([0.0103], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([0.0042], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>), tensor([0.0051], grad_fn=<SubBackward0>), tensor([0.0128], grad_fn=<SubBackward0>), tensor([19.9333], grad_fn=<SubBackward0>), tensor([0.0063], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([-0.9929], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▊       | 43002/150000 [1:33:01<3:40:41,  8.08it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.3331e-10, grad_fn=<MulBackward0>), tensor([0.0102], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0042], grad_fn=<SubBackward0>), tensor([-0.9928], grad_fn=<SubBackward0>), tensor([0.0051], grad_fn=<SubBackward0>), tensor([0.0127], grad_fn=<SubBackward0>), tensor([19.9340], grad_fn=<SubBackward0>), tensor([0.0062], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([-0.9930], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 29%|██▉       | 44002/150000 [1:35:12<3:57:14,  7.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.1675e-10, grad_fn=<MulBackward0>), tensor([0.0107], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0132], grad_fn=<SubBackward0>), tensor([19.9309], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9926], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30%|███       | 45002/150000 [1:37:23<3:37:32,  8.04it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.0171e-10, grad_fn=<MulBackward0>), tensor([0.0109], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.0045], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>), tensor([0.0054], grad_fn=<SubBackward0>), tensor([0.0135], grad_fn=<SubBackward0>), tensor([19.9292], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|███       | 46002/150000 [1:39:38<3:57:54,  7.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(8.5985e-11, grad_fn=<MulBackward0>), tensor([0.0107], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0133], grad_fn=<SubBackward0>), tensor([19.9307], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9926], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 31%|███▏      | 47002/150000 [1:41:58<3:50:33,  7.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(7.5033e-11, grad_fn=<MulBackward0>), tensor([0.0106], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0132], grad_fn=<SubBackward0>), tensor([19.9312], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 32%|███▏      | 48002/150000 [1:44:16<3:34:17,  7.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(6.7867e-11, grad_fn=<MulBackward0>), tensor([0.0108], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([0.0045], grad_fn=<SubBackward0>), tensor([-0.9923], grad_fn=<SubBackward0>), tensor([0.0054], grad_fn=<SubBackward0>), tensor([0.0134], grad_fn=<SubBackward0>), tensor([19.9301], grad_fn=<SubBackward0>), tensor([0.0066], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 49002/150000 [1:46:31<3:29:45,  8.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(6.1574e-11, grad_fn=<MulBackward0>), tensor([0.0109], grad_fn=<SubBackward0>), tensor([0.0072], grad_fn=<SubBackward0>), tensor([0.0045], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>), tensor([0.0054], grad_fn=<SubBackward0>), tensor([0.0135], grad_fn=<SubBackward0>), tensor([19.9294], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 50002/150000 [1:48:45<3:34:27,  7.77it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(5.7573e-11, grad_fn=<MulBackward0>), tensor([0.0113], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([0.0047], grad_fn=<SubBackward0>), tensor([-0.9919], grad_fn=<SubBackward0>), tensor([0.0056], grad_fn=<SubBackward0>), tensor([0.0140], grad_fn=<SubBackward0>), tensor([19.9270], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 34%|███▍      | 51002/150000 [1:50:59<3:45:05,  7.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(5.2620e-11, grad_fn=<MulBackward0>), tensor([0.0113], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([0.0047], grad_fn=<SubBackward0>), tensor([-0.9919], grad_fn=<SubBackward0>), tensor([0.0056], grad_fn=<SubBackward0>), tensor([0.0140], grad_fn=<SubBackward0>), tensor([19.9268], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▍      | 52002/150000 [1:53:07<3:34:44,  7.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(4.7251e-11, grad_fn=<MulBackward0>), tensor([0.0111], grad_fn=<SubBackward0>), tensor([0.0073], grad_fn=<SubBackward0>), tensor([0.0046], grad_fn=<SubBackward0>), tensor([-0.9921], grad_fn=<SubBackward0>), tensor([0.0055], grad_fn=<SubBackward0>), tensor([0.0137], grad_fn=<SubBackward0>), tensor([19.9282], grad_fn=<SubBackward0>), tensor([0.0068], grad_fn=<SubBackward0>), tensor([0.0073], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35%|███▌      | 53002/150000 [1:55:16<3:22:13,  7.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(4.4457e-11, grad_fn=<MulBackward0>), tensor([0.0113], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([0.0047], grad_fn=<SubBackward0>), tensor([-0.9920], grad_fn=<SubBackward0>), tensor([0.0056], grad_fn=<SubBackward0>), tensor([0.0140], grad_fn=<SubBackward0>), tensor([19.9269], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0074], grad_fn=<SubBackward0>), tensor([-0.9922], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|███▌      | 54002/150000 [1:57:24<3:35:52,  7.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(4.0520e-11, grad_fn=<MulBackward0>), tensor([0.0111], grad_fn=<SubBackward0>), tensor([0.0073], grad_fn=<SubBackward0>), tensor([0.0046], grad_fn=<SubBackward0>), tensor([-0.9921], grad_fn=<SubBackward0>), tensor([0.0055], grad_fn=<SubBackward0>), tensor([0.0137], grad_fn=<SubBackward0>), tensor([19.9282], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0073], grad_fn=<SubBackward0>), tensor([-0.9923], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 55002/150000 [1:59:33<3:29:14,  7.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.6231e-11, grad_fn=<MulBackward0>), tensor([0.0107], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([0.0044], grad_fn=<SubBackward0>), tensor([-0.9924], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0131], grad_fn=<SubBackward0>), tensor([19.9312], grad_fn=<SubBackward0>), tensor([0.0065], grad_fn=<SubBackward0>), tensor([0.0070], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 37%|███▋      | 56002/150000 [2:01:41<3:13:32,  8.09it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.4573e-11, grad_fn=<MulBackward0>), tensor([0.0108], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([0.0045], grad_fn=<SubBackward0>), tensor([-0.9923], grad_fn=<SubBackward0>), tensor([0.0054], grad_fn=<SubBackward0>), tensor([0.0133], grad_fn=<SubBackward0>), tensor([19.9302], grad_fn=<SubBackward0>), tensor([0.0066], grad_fn=<SubBackward0>), tensor([0.0071], grad_fn=<SubBackward0>), tensor([-0.9926], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 38%|███▊      | 57002/150000 [2:03:46<3:09:31,  8.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(3.1840e-11, grad_fn=<MulBackward0>), tensor([0.0106], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([0.0043], grad_fn=<SubBackward0>), tensor([-0.9925], grad_fn=<SubBackward0>), tensor([0.0053], grad_fn=<SubBackward0>), tensor([0.0130], grad_fn=<SubBackward0>), tensor([19.9317], grad_fn=<SubBackward0>), tensor([0.0064], grad_fn=<SubBackward0>), tensor([0.0069], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|███▊      | 58002/150000 [2:05:54<3:09:59,  8.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.9250e-11, grad_fn=<MulBackward0>), tensor([0.0103], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([0.0042], grad_fn=<SubBackward0>), tensor([-0.9927], grad_fn=<SubBackward0>), tensor([0.0051], grad_fn=<SubBackward0>), tensor([0.0126], grad_fn=<SubBackward0>), tensor([19.9337], grad_fn=<SubBackward0>), tensor([0.0062], grad_fn=<SubBackward0>), tensor([0.0067], grad_fn=<SubBackward0>), tensor([-0.9929], grad_fn=<SubBackward0>)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39%|███▉      | 58317/150000 [2:06:34<3:05:04,  8.26it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8HooWh9fmrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Function Will take as input a Gaem class and Output a Gaem class with functions Replaced by Neural Net Parameters CURRENTLY UNNECESSARY??? IDK\n",
        "# def NeuralNetWrapper(GameType, Game_params):\n",
        "#     class Gamified(GameType):\n",
        "#         def __init__(self):\n",
        "#             super().__init__(Game_params)\n",
        "            \n",
        "#         def play(self, strats):\n",
        "#             for \n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFMuMdv0medh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebb0e63c-67aa-44e6-89ab-54c6f1428831"
      },
      "source": [
        "a = torch.distributions.bernoulli.Bernoulli(probs=torch.tensor([.7,.3,.7]))\n",
        "b = torch.tensor([0.,0.,0.])\n",
        "for i in range(5000):\n",
        "    b += a.sample()\n",
        "print(b/5000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.6970, 0.3068, 0.6914])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}